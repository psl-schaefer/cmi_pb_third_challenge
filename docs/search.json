[
  {
    "objectID": "models/model_selection.html",
    "href": "models/model_selection.html",
    "title": "Model Selection",
    "section": "",
    "text": "1 Packages\n\n\nCode\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(flextable)\n  library(ggdark)\n  library(magick)\n  library(glmnet)\n  library(ranger)\n})\n\nsource(file.path(\"..\", \"src\", \"read_data.R\"))\nsource(file.path(\"..\", \"src\", \"colors.R\"))\nsource(file.path(\"..\", \"src\", \"generate_targets.R\"))\nsource(file.path(\"..\", \"src\", \"model.R\"))\n\n\n\n\n2 Data\n\n\nCode\ninput_dir = file.path(\"..\", \"data\")\noutput_dir = file.path(\"..\", \"results\", \"model_selection_default\")\ndir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n\n\n\n\nCode\ncelltype_meta &lt;- read_celltype_meta(input_dir)\ngene_meta &lt;- read_gene_meta_plus(input_dir)\nprotein_meta &lt;- read_protein_meta(input_dir)\n\nmeta_data &lt;- read_harmonized_meta_data(input_dir)\nspecimen_per_day &lt;- get_specimen_per_day(meta_data=meta_data)\n\nRECOMPUTE &lt;- TRUE\nif (RECOMPUTE) {\n  source(file.path(\"..\", \"src\", \"normalize_integrate.R\"))\n  \n  raw_experimental_data &lt;- read_raw_experimental_data(input_dir)\n  \n  filtered_experimental_data &lt;- filter_experimental_data(\n    meta_data=meta_data, \n    experimental_data=raw_experimental_data,\n    gene_meta=gene_meta)\n  \n  write_rds(filtered_experimental_data, \n            file = file.path(input_dir, \"prc_datasets\", \n                             \"filtered_experimental_data.RDS\"))\n  \n  specimen_to_assay &lt;- purrr::map(list(\"raw\"=raw_experimental_data, \"filtered\"=filtered_experimental_data), function(exp_data) {\n    # exp_data &lt;- filtered_experimental_data; exp_name = \"filtered\"\n    purrr::imap(exp_data, function(exp_df, exp_name) {\n      exp_df %&gt;%\n        dplyr::select(specimen_id) %&gt;%\n        dplyr::distinct() %&gt;%\n        dplyr::mutate(assay = exp_name, specimen_id = as.numeric(specimen_id))\n    }) %&gt;%\n      dplyr::bind_rows() %&gt;%\n      dplyr::mutate(present = TRUE) %&gt;%\n      tidyr::pivot_wider(names_from=assay, values_from=present) %&gt;%\n      mutate_all(~ ifelse(is.na(.), FALSE, .))\n  })\n  \n  meta_data_plus_assays &lt;- purrr::map(specimen_to_assay, function(df) {\n    meta_data %&gt;%\n      dplyr::left_join(df, by=\"specimen_id\") %&gt;%\n      mutate_all(~ ifelse(is.na(.), FALSE, .))\n  })\n  \n  write_rds(specimen_to_assay, \n            file = file.path(input_dir, \"prc_datasets\", \n                             \"specimen_to_assay.RDS\"))\n  write_rds(meta_data_plus_assays, \n            file = file.path(input_dir, \"prc_datasets\", \n                             \"meta_data_plus_assays.RDS\"))\n  \n  normalized_experimental_data &lt;- normalize_experimental_data(\n    meta_data=meta_data, \n    raw_experimental_data=filtered_experimental_data,\n    gene_meta=gene_meta)\n  \n  write_rds(normalized_experimental_data, \n            file = file.path(input_dir, \"prc_datasets\", \n                             \"normalized_experimental_data.RDS\"))\n  \n  integrated_experimental_data &lt;- integrate_experimental_data(\n    meta_data=meta_data, \n    normalized_experimental_data=normalized_experimental_data)\n  \n  write_rds(integrated_experimental_data, \n            file = file.path(input_dir, \"prc_datasets\", \n                             \"integrated_experimental_data.RDS\"))\n\n  # use raw/filtered experimental data for computation of targets\n  target_list &lt;- generate_all_targets(\n    meta_data=meta_data, \n    experimental_data=filtered_experimental_data, \n    experimental_data_settings=experimental_data_settings, \n    gene_meta=gene_meta,\n    protein_meta=protein_meta\n    )\n  \n  # use raw/filtered experimental data for computation of targets\n  baseline_list &lt;- generate_all_baselines(\n    meta_data=meta_data, \n    experimental_data=filtered_experimental_data, \n    experimental_data_settings=experimental_data_settings, \n    gene_meta=gene_meta,\n    protein_meta=protein_meta\n    )\n  \n  stopifnot(identical(names(target_list), names(baseline_list)))\n  purrr::map_lgl(names(target_list), function(task_name) {\n    (target_list[[task_name]] %&gt;%\n      dplyr::inner_join(baseline_list[[task_name]], by=\"subject_id\") %&gt;%\n      dplyr::summarise(cor = cor(baseline.x, baseline.y)) %&gt;%\n      dplyr::pull(cor)) == 1\n  }) %&gt;%\n    all() %&gt;%\n    stopifnot()\n  \n  write_rds(target_list, file = file.path(input_dir, \"prc_datasets\", \n                                          \"target_list.RDS\"))\n  \n  write_rds(baseline_list, file = file.path(input_dir, \"prc_datasets\", \n                                            \"baseline_list.RDS\"))\n  \n  rm(raw_experimental_data, filtered_experimental_data)\n  experimental_data &lt;- integrated_experimental_data\n  experimental_data &lt;- experimental_data[-which(names(experimental_data) ==\n                                                \"pbmc_gene_expression_counts\")]\n} else {\n  experimental_data &lt;- read_rds(file = file.path(input_dir, \"prc_datasets\", \n                                                            \"integrated_experimental_data.RDS\"))\n  experimental_data &lt;- experimental_data[-which(names(experimental_data) ==\n                                                \"pbmc_gene_expression_counts\")]\n  \n  target_list &lt;- read_rds(file = file.path(input_dir, \"prc_datasets\",  \"target_list.RDS\"))\n  \n  baseline_list &lt;- read_rds(file = file.path(input_dir, \"prc_datasets\", \"baseline_list.RDS\"))\n  \n  specimen_to_assay &lt;- read_rds(file = file.path(input_dir, \"prc_datasets\", \"specimen_to_assay.RDS\"))\n  \n  meta_data_plus_assays &lt;- read_rds(file = file.path(input_dir, \"prc_datasets\", \"meta_data_plus_assays.RDS\"))\n}\n\n\nLoading required package: S4Vectors\n\n\nLoading required package: stats4\n\n\nLoading required package: BiocGenerics\n\n\n\nAttaching package: 'BiocGenerics'\n\n\nThe following object is masked from 'package:flextable':\n\n    width\n\n\nThe following objects are masked from 'package:lubridate':\n\n    intersect, setdiff, union\n\n\nThe following objects are masked from 'package:dplyr':\n\n    combine, intersect, setdiff, union\n\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nThe following objects are masked from 'package:base':\n\n    Filter, Find, Map, Position, Reduce, anyDuplicated, aperm, append,\n    as.data.frame, basename, cbind, colnames, dirname, do.call,\n    duplicated, eval, evalq, get, grep, grepl, intersect, is.unsorted,\n    lapply, mapply, match, mget, order, paste, pmax, pmax.int, pmin,\n    pmin.int, rank, rbind, rownames, sapply, setdiff, sort, table,\n    tapply, union, unique, unsplit, which.max, which.min\n\n\n\nAttaching package: 'S4Vectors'\n\n\nThe following objects are masked from 'package:Matrix':\n\n    expand, unname\n\n\nThe following objects are masked from 'package:lubridate':\n\n    second, second&lt;-\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, rename\n\n\nThe following object is masked from 'package:tidyr':\n\n    expand\n\n\nThe following objects are masked from 'package:base':\n\n    I, expand.grid, unname\n\n\nLoading required package: IRanges\n\n\n\nAttaching package: 'IRanges'\n\n\nThe following object is masked from 'package:lubridate':\n\n    %within%\n\n\nThe following objects are masked from 'package:dplyr':\n\n    collapse, desc, slice\n\n\nThe following object is masked from 'package:purrr':\n\n    reduce\n\n\nLoading required package: GenomicRanges\n\n\nLoading required package: GenomeInfoDb\n\n\nLoading required package: SummarizedExperiment\n\n\nLoading required package: MatrixGenerics\n\n\nLoading required package: matrixStats\n\n\n\nAttaching package: 'matrixStats'\n\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\n\n\nAttaching package: 'MatrixGenerics'\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\n\nLoading required package: Biobase\n\n\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\n\nAttaching package: 'Biobase'\n\n\nThe following object is masked from 'package:MatrixGenerics':\n\n    rowMedians\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    anyMissing, rowMedians\n\n\nLoading required package: mgcv\n\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:IRanges':\n\n    collapse\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nLoading required package: genefilter\n\n\n\nAttaching package: 'genefilter'\n\n\nThe following objects are masked from 'package:MatrixGenerics':\n\n    rowSds, rowVars\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    rowSds, rowVars\n\n\nThe following object is masked from 'package:readr':\n\n    spec\n\n\nLoading required package: BiocParallel\n\n\npbmc_cell_frequency | Removed 550 specimens because missing in meta data\n\n\nplasma_ab_titer | Removed 6931 specimens because missing in meta data\n\n\nplasma_cytokine_concentration_by_olink | Removed 495 specimens because missing in meta data\n\n\npbmc_cell_frequency | Removed 56 features because not in feature subset\n\n\nplasma_ab_titer | Removed 48 features because not in feature subset\n\n\nplasma_cytokine_concentration_by_olink | Removed 234 features because not in feature subset\n\n\nt_cell_polarization | Removed 3 features because not in feature subset\n\n\nplasma_cytokine_concentration_by_olink | Removed 300 features because qc warning\n\n\nplasma_ab_titer | Removed 10540 measurements because wrong unit used\n\n\nplasma_cytokine_concentration_by_olink | Removed 2400 measurements because wrong unit used\n\n\nplasma_cytokine_concentration_by_legendplex | Removed 8 because specimen is outlier\n\n\nconverting counts to integer mode\n\n\nconverting counts to integer mode\nconverting counts to integer mode\nconverting counts to integer mode\n\n\nFound 4 batches\nUsing null model in ComBat-seq.\nAdjusting for 0 covariate(s) or covariate level(s)\nEstimating dispersions\nFitting the GLM model\nShrinkage off - using GLM estimates for parameters\nAdjusting the data\n\n\nFound3batches\n\n\nAdjusting for0covariate(s) or covariate level(s)\n\n\nStandardizing Data across genes\n\n\nFitting L/S model and finding priors\n\n\nFinding parametric adjustments\n\n\nAdjusting the Data\n\n\n\n\n3 Tasks\n\n\nCode\ntask_meta &lt;- list(\n  task_11 = list(\n    name = \"task_11\",\n    header = \"## Task 1.1\",\n    description = \"Rank the individuals by IgG antibody levels against pertussis toxin (PT) that we detect in plasma 14 days post booster vaccinations.\"\n  ),\n  task_12 = list(\n    name = \"task_12\",\n    header = \"## Task 1.2\",\n    description = \"Rank the individuals by fold change of IgG antibody levels against pertussis toxin (PT) that we detect in plasma 14 days post booster vaccinations compared to titer values at day 0.\"\n  ),\n  task_21 = list(\n    name = \"task_21\",\n    header = \"## Task 2.1\",\n    description = \"Rank the individuals by predicted frequency of Monocytes on day 1 post boost after vaccination.\"\n  ),\n  task_22 = list(\n    name = \"task_22\",\n    header = \"## Task 2.2\",\n    description = \"Rank the individuals by fold change of predicted frequency of Monocytes on day 1 post booster vaccination compared to cell frequency values at day 0.\"\n  ),\n  task_31 = list(\n    name = \"task_31\",\n    header = \"## Task 3.1\",\n    description = \"Rank the individuals by predicted gene expression of CCL3 on day 3 post-booster vaccination.\"\n  ),\n  task_32 = list(\n    name = \"task_32\",\n    header = \"## Task 3.2\",\n    description = \"Rank the individuals by fold change of predicted gene expression of CCL3 on day 3 post booster vaccination compared to gene expression values at day 0.\"\n  ),\n  task_41 = list(\n    name = \"task_41\",\n    header = \"## Task 4.1\",\n    description = \"Rank the individuals based on their Th1/Th2 (IFN-g/IL-5) polarization ratio on Day 30 post-booster vaccination.\"\n  )\n)\n\n\n\n\n4 Rationale\n\nHow to choose the right model?\n\nTop ranking performance\nLow variance between the test sets\nIf several models with top performance and low variance, choose the more regularized model\nIf several models with top performance and low variance, choose model that is not using assay that is missing often in test data (-&gt; Olink!)\n\n\n\n\n5 Conclusions\nTODO\n\n\n6 Prepare Features\n\n\nCode\nN_HVG &lt;- 2000\n\nhvg &lt;- gene_meta %&gt;% \n  dplyr::mutate(\"prefix_versioned_ensembl_gene_id_clean\" =\n                  paste0(\"pbmc_gene_expression_\", versioned_ensembl_gene_id_clean)) %&gt;%\n  dplyr::slice_max(mean_rank, n=N_HVG, with_ties=TRUE)\n\nmeta_data_cov &lt;- get_metadata_covariates(meta_data) %&gt;%\n  dplyr::select(-c(ethnicity_Not_Hispanic_or_Latino, ethnicity_Hispanic_or_Latino))\n\nexperimental_predictors_day_0 &lt;- \n  generate_wide_experimental_data(experimental_data=experimental_data,\n                                  impute=\"knn\", \n                                  max_NA_frac_sample = 0.5,\n                                  max_NA_frac_feature = 0.25,\n                                  verbose=TRUE) %&gt;%\n  purrr::imap(function(df, modality) {\n    colnames(df) &lt;- paste0(modality, \"_\", colnames(df))\n    df &lt;- as.data.frame(df) %&gt;%\n      tibble::rownames_to_column(\"specimen_id\") %&gt;%\n      dplyr::mutate(specimen_id = as.numeric(specimen_id)) %&gt;%\n      dplyr::left_join((specimen_per_day$day_0 %&gt;% \n                        dplyr::select(subject_id, specimen_id, dataset)),\n                       by=\"specimen_id\") %&gt;%\n      dplyr::select(-c(specimen_id, dataset)) %&gt;%\n      dplyr::filter(!is.na(subject_id)) %&gt;%\n      dplyr::select(subject_id, everything())\n    return(df)\n  })\n\n\nplasma_cytokine_concentration_by_olink | NA Fraction: 0.0110795454545455 | Removed samples: 760, 750, 903, 824, 894, 833\n\n\nplasma_cytokine_concentration_by_olink | NA Fraction: 0.00288417166589755 | Imputed with knn imputation\n\n\nt_cell_activation | NA Fraction: 0.0576923076923077 | Removed samples: 681\n\n\nt_cell_activation | NA Fraction: 0.0553691275167785 | Imputed with knn imputation\n\n\nt_cell_polarization | NA Fraction: 0.0134099616858238 | Imputed with knn imputation\n\n\nCode\nexperimental_predictors_day_0$pbmc_gene_expression &lt;-\n  experimental_predictors_day_0$pbmc_gene_expression[, c(\"subject_id\", hvg$prefix_versioned_ensembl_gene_id_clean)]\n\n#purrr::map(experimental_predictors_day_0, ~ dim(.x))\n\nexperimental_predictors_day_0_pca &lt;- experimental_predictors_day_0 %&gt;%\n  purrr::imap(function(df, modality) {\n    # df &lt;- experimental_predictors_day_0$\n    mtx &lt;- df %&gt;% dplyr::select(-subject_id) %&gt;% as.matrix()\n    pca &lt;- stats::prcomp(mtx)\n    sdev_ratio &lt;- cumsum(pca$sdev) / sum(pca$sdev)\n    n_pcs &lt;- max(which(sdev_ratio &lt; 0.9))\n    df_pca &lt;- as.data.frame(pca$x[, 1:n_pcs]) %&gt;%\n      dplyr::mutate(subject_id = df$subject_id) %&gt;%\n      dplyr::select(subject_id, everything())\n    return(df_pca)\n})\n\nmodality_powerset &lt;- purrr::map(1:length(experimental_predictors_day_0), function(i) {\n  utils::combn(names(experimental_predictors_day_0), i, simplify = FALSE)\n}) %&gt;%\n   unlist(recursive = FALSE)\n\n#purrr::map(experimental_predictors_day_0_pca, ~ dim(.x))\n\nmeta_data_plus_assays_day_0 &lt;- meta_data_plus_assays$filtered %&gt;%\n  dplyr::filter(specimen_id %in% specimen_per_day$day_0$specimen_id)\nstopifnot(length(meta_data_plus_assays_day_0$subject_id) == \n            length(unique(meta_data_plus_assays_day_0$subject_id)))\n\n# which assays are most/least often missing?\nmeta_data_plus_assays_day_0 %&gt;%\n  dplyr::select(dplyr::all_of(names(experimental_predictors_day_0))) %&gt;%\n  dplyr::mutate(row_sum = apply(select(., matches(\".+\")), 1, sum)) %&gt;%\n  dplyr::filter(row_sum &gt; 0) %&gt;%\n  tidyr::pivot_longer(cols=!row_sum) %&gt;%\n  dplyr::group_by(name) %&gt;%\n  dplyr::summarise(mean = mean(value)) %&gt;%\n  dplyr::arrange(desc(mean))\n\n\n\n  \n\n\n\n\n\nCode\nMAX_N_ASSAYS_MISSING &lt;- 2\nK_FOR_KNN_IMPUTE &lt;- 7\n\nfeature_list &lt;- list(\n  \"metadata\" = meta_data_cov,\n  \"metadata+baseline\" = meta_data_cov # will take care of that logic in loop\n)\n\n# small_utility_function to renamce the pca colnames?\n\n# adding power set of single-omic pca predictors\nfor (modality_set in modality_powerset) {\n  # modality_set &lt;- modality_powerset[[100]]\n  modality_set_name &lt;- paste0(paste0(modality_set, collapse = \"_pca+\"), \"_pca+metadata+baseline\")\n  \n  # inner join here, other subject have no assays for day 0...\n  modality_set_check_assays  &lt;- meta_data_cov %&gt;%\n    dplyr::inner_join(dplyr::select(meta_data_plus_assays_day_0, dplyr::all_of(c(\"subject_id\", modality_set))), \n                        by=\"subject_id\")\n  modality_set_check_assays[, modality_set][is.na(modality_set_check_assays[, modality_set])] &lt;- FALSE\n  modality_set_check_assays[, \"n_assays_present\"] &lt;- rowSums(modality_set_check_assays[, modality_set])\n  modality_set_check_assays[, \"n_assays_max\"] &lt;- length(modality_set)\n  modality_set_check_assays[, \"n_assays_missing\"] &lt;- length(modality_set) - modality_set_check_assays[, \"n_assays_present\"]\n  modality_set_check_assays &lt;- modality_set_check_assays %&gt;%\n    dplyr::mutate(n_assays_frac = n_assays_present / n_assays_max)\n  \n  subjects_to_exclude &lt;- modality_set_check_assays %&gt;%\n    dplyr::filter(n_assays_missing &gt;= !!MAX_N_ASSAYS_MISSING) %&gt;%\n    dplyr::pull(subject_id)\n  \n  modality_set_meta_df &lt;- meta_data_cov %&gt;%\n    dplyr::filter(!(subject_id %in% subjects_to_exclude))\n  \n  modality_set_df &lt;- \n    experimental_predictors_day_0_pca[modality_set] %&gt;%\n    purrr::reduce(full_join, by=\"subject_id\") %&gt;%\n    dplyr::inner_join(modality_set_meta_df, by=\"subject_id\")\n  \n  modality_set_mtx &lt;- modality_set_df %&gt;%\n    tibble::column_to_rownames(\"subject_id\") %&gt;%\n    as.matrix() %&gt;%\n    t() %&gt;%\n    impute::impute.knn(data=., k=K_FOR_KNN_IMPUTE, maxp=10000, colmax=1) %&gt;%\n    .$data %&gt;%\n    t()\n  \n  feature_list[[modality_set_name]] &lt;- as.data.frame(modality_set_mtx) %&gt;%\n    tibble::rownames_to_column(\"subject_id\") %&gt;%\n    dplyr::mutate(subject_id = as.numeric(subject_id))\n}\n\n# adding power set of single-omic predictors\nfor (modality_set in modality_powerset) {\n  # modality_set &lt;- modality_powerset[[100]]\n  modality_set_name &lt;- paste0(paste0(modality_set, collapse = \"+\"), \"+metadata+baseline\")\n  \n# inner join here, other subject have no assays for day 0...\n  modality_set_check_assays  &lt;- meta_data_cov %&gt;%\n    dplyr::inner_join(dplyr::select(meta_data_plus_assays_day_0, dplyr::all_of(c(\"subject_id\", modality_set))), \n                        by=\"subject_id\")\n  modality_set_check_assays[, modality_set][is.na(modality_set_check_assays[, modality_set])] &lt;- FALSE\n  modality_set_check_assays[, \"n_assays_present\"] &lt;- rowSums(modality_set_check_assays[, modality_set])\n  modality_set_check_assays[, \"n_assays_max\"] &lt;- length(modality_set)\n  modality_set_check_assays[, \"n_assays_missing\"] &lt;- length(modality_set) - modality_set_check_assays[, \"n_assays_present\"]\n  modality_set_check_assays &lt;- modality_set_check_assays %&gt;%\n    dplyr::mutate(n_assays_frac = n_assays_present / n_assays_max)\n  \n  \n  subjects_to_exclude &lt;- modality_set_check_assays %&gt;%\n    dplyr::filter(n_assays_missing &gt;= !!MAX_N_ASSAYS_MISSING) %&gt;%\n    dplyr::pull(subject_id)\n  \n  modality_set_meta_df &lt;- meta_data_cov %&gt;%\n    dplyr::filter(!(subject_id %in% subjects_to_exclude))\n  \n  modality_set_df &lt;- \n    experimental_predictors_day_0[modality_set] %&gt;%\n    purrr::reduce(full_join, by=\"subject_id\") %&gt;%\n    dplyr::inner_join(modality_set_meta_df, by=\"subject_id\")\n  \n  modality_set_mtx &lt;- modality_set_df %&gt;%\n    tibble::column_to_rownames(\"subject_id\") %&gt;%\n    as.matrix() %&gt;%\n    t() %&gt;%\n    impute::impute.knn(data=., k=K_FOR_KNN_IMPUTE, maxp=10000, colmax=1) %&gt;%\n    .$data %&gt;%\n    t()\n  \n  feature_list[[modality_set_name]] &lt;- as.data.frame(modality_set_mtx) %&gt;%\n    tibble::rownames_to_column(\"subject_id\") %&gt;%\n    dplyr::mutate(subject_id = as.numeric(subject_id))\n}\n\nstopifnot(all(purrr::map_dbl(feature_list, ~ mean(is.na(.x))) == 0))\n\n#purrr::map(feature_list, ~ dim(.x))\n\n\n\n\nCode\n# -&gt; why do they have to use fortran code ....\nknn_impute_internal &lt;- function(x, k, imiss, irmiss, p, n) {\n  # see https://code.bioconductor.org/browse/impute/blob/RELEASE_3_19/src/knnimpute.f\n  junk &lt;- .Fortran(\"knnimp\", \n                   x, \n                   ximp = x, \n                   p, \n                   n, \n                   imiss = imiss, \n                   irmiss, \n                   as.integer(k), \n                   double(p), \n                   double(n + k), \n                   integer(p + k), \n                   integer(n), \n                   PACKAGE = \"impute\")\n  ximp &lt;- junk$ximp\n  ximp[junk$imiss == 2] &lt;- NA\n  return(ximp)\n}\n\nx &lt;- t(modality_set_mtx)\nk &lt;- 10\nknn_impute &lt;- function(x, k = 10) {\n  pn &lt;- dim(x)\n  dn &lt;- dimnames(x)\n  p &lt;- as.integer(pn[1])\n  n &lt;- as.integer(pn[2])\n  imiss &lt;- is.na(x)\n  x[imiss] &lt;- 0\n  irmiss &lt;- drop(imiss %*% rep(1, n))\n  storage.mode(imiss) &lt;- \"integer\"\n  storage.mode(irmiss) &lt;- \"integer\"\n  storage.mode(x) &lt;- \"double\"\n  ximp &lt;- knn_impute_internal(x, k, imiss, irmiss, p, n)\n  return(ximp)\n}\n\n\n\n\n7 Model Evaluation / Assessment\n\n\nCode\ntictoc::tic()\n\nresult_list &lt;-  list()\n\nfor (task in task_meta) {\n  # task &lt;- task_meta[[1]]\n  \n  task_df &lt;- target_list[[task$name]]\n  \n  target_df &lt;- task_df %&gt;%\n    dplyr::select(subject_id, target)\n  \n  baseline_df &lt;- task_df %&gt;% \n    dplyr::select(subject_id, baseline)\n  \n  baseline_model_df &lt;- task_df %&gt;%\n    dplyr::left_join(dplyr::distinct(dplyr::select(meta_data, c(subject_id, dataset))),\n                     by=\"subject_id\")\n  \n  all_datasets &lt;- unique(baseline_model_df$dataset)\n  \n  for (test_dataset in all_datasets) {\n    result_list &lt;- rlist::list.append(result_list, tibble::tibble(\n      task = task$name,\n      trainset = NA,\n      testset = test_dataset,\n      test_subset = task_df$subject_id[baseline_model_df$dataset==test_dataset],\n      target = task_df$target[baseline_model_df$dataset==test_dataset], \n      prediction = task_df$baseline[baseline_model_df$dataset==test_dataset],\n      testset_mean = NA,\n      model = \"baseline\",\n      feature_set = \"baseline\"\n    ))\n  }\n  for (model_name in c(\"lasso\", \"elnet\", \"rf\", \"rf+boruta\")) {\n    # model_name &lt;- \"lasso\"\n    for (feature_name in names(feature_list)) {\n      # feature_name &lt;- names(feature_list)[2]\n      feature_df &lt;- feature_list[[feature_name]]\n      \n      if (str_detect(feature_name, \"baseline\")) {\n        feature_df &lt;- feature_df %&gt;%\n          dplyr::left_join(baseline_df, by=\"subject_id\")\n      }\n      \n      model_df &lt;- target_df %&gt;%\n        dplyr::left_join(feature_df, by=\"subject_id\") %&gt;%\n        dplyr::left_join(dplyr::distinct(dplyr::select(meta_data, c(subject_id, dataset))),\n                         by=\"subject_id\")\n      \n      #stopifnot(!any(is.na(model_df))) # guard rail\n      model_df &lt;- model_df %&gt;% tidyr::drop_na()\n      stopifnot(nrow(model_df)==nrow(dplyr::distinct(model_df)))\n      \n      all_datasets &lt;- unique(model_df$dataset)\n      \n      cross_dataset_out &lt;- purrr::map(all_datasets, function(test_dataset) {\n        # test_dataset &lt;- all_datasets[2]\n        train_dataset &lt;- all_datasets[!all_datasets %in% test_dataset]\n        \n        train_df &lt;- model_df %&gt;%\n          dplyr::filter(dataset %in% train_dataset) %&gt;%\n          dplyr::select(-c(dataset, subject_id))\n        \n        train_mtx &lt;- as.matrix(dplyr::select(train_df, -target))\n        train_target &lt;- dplyr::pull(train_df, target)\n        \n        test_df_with_subject &lt;- model_df %&gt;%\n          dplyr::filter(dataset %in% test_dataset)\n        \n        test_df &lt;- test_df_with_subject %&gt;%\n          dplyr::select(-c(dataset, subject_id))\n        \n        test_mtx &lt;- as.matrix(dplyr::select(test_df, -target))\n        test_target &lt;- dplyr::pull(test_df, target)\n        \n        if (model_name == \"rf\") {\n          model &lt;- ranger::ranger(formula = target ~ ., \n                                  data = train_df, \n                                  num.trees = 500)\n          predictions &lt;- predict(model, test_df)$predictions\n        } \n        else if (model_name == \"rf+boruta\") {\n          if (ncol(train_df) &gt; 2) {\n            boruta_out &lt;- Boruta::Boruta(formula = target ~ .,\n                                         data = train_df,\n                                         maxRuns=1000,\n                                         num.trees=500 \n                                         )\n            boruta_feats &lt;- names(boruta_out$finalDecision)[boruta_out$finalDecision==\"Confirmed\"]\n          } else {\n            boruta_feats &lt;- colnames(train_df)[colnames(train_df)!=\"target\"]\n          }\n          if (length(boruta_feats) == 0) {\n            predictions &lt;- rep(mean(train_df$target), nrow(test_df))\n          } else {\n            train_df_subset &lt;- train_df %&gt;% dplyr::select(dplyr::all_of(c(boruta_feats, \"target\")))\n            test_df_subset &lt;- test_df %&gt;% dplyr::select(dplyr::all_of(c(boruta_feats, \"target\")))\n            model &lt;- ranger::ranger(formula = target ~ ., \n                                    data = train_df_subset, \n                                    num.trees = 500)\n            predictions &lt;- predict(model, test_df_subset)$predictions\n          }\n        } \n        else if (model_name == \"lasso\") {\n          # standardize the features, even though glmnet is doing this automatically!\n          feature_means &lt;- matrixStats::colMeans2(train_mtx)\n          feature_sds &lt;- matrixStats::colSds(train_mtx)\n          train_mtx &lt;- t((t(train_mtx) - feature_means) / feature_sds)\n          train_target &lt;- (train_target - mean(train_target)) / sd(train_target)\n          #test_mtx &lt;- t((t(test_mtx) - feature_means) / feature_sds)\n          \n          # inner hyperparameter optim loop using LOOCV to find best lambda\n          model &lt;- glmnet::cv.glmnet(x=train_mtx,\n                                     y=train_target,\n                                     nfolds=nrow(train_mtx),\n                                     grouped=FALSE,\n                                     alpha=1, # LASSO\n                                     type.measure=\"mae\", # not sure whether this is better\n                                     standardize=TRUE, # by default each feature is standardized internally\n                                     family=\"gaussian\"\n                                     )\n          # investigate\n          #beta_mtx &lt;- as.data.frame(as.matrix(model$glmnet.fit$beta))\n          #colnames(beta_mtx) &lt;- paste0(\"lambda_\", round(model$lambda, 3))\n          #plot(model)\n          #lambda_value &lt;- model$lambda.1se, # model$lambda.min\n          # never use zero features (with lamba=model$lambda[1]), since constant predictions\n          # will have NA spearman...\n          lambda_value &lt;- ifelse(model$lambda.min==model$lambda[1], \n                                 model$lambda[2], model$lambda.min)\n          predictions &lt;- predict(model,\n                                 newx=test_mtx, \n                                 s=lambda_value)[,1]\n        }\n        else if (model_name == \"elnet\") {\n          # standardize the features, even though glmnet is doing this automatically!\n          feature_means &lt;- matrixStats::colMeans2(train_mtx)\n          feature_sds &lt;- matrixStats::colSds(train_mtx)\n          train_mtx &lt;- t((t(train_mtx) - feature_means) / feature_sds)\n          train_target &lt;- (train_target - mean(train_target)) / sd(train_target)\n          #test_mtx &lt;- t((t(test_mtx) - feature_means) / feature_sds)\n          \n          # inner hyperparameter optim loop using LOOCV to find best lambda\n          model &lt;- glmnet::cv.glmnet(x=train_mtx,\n                                     y=train_target,\n                                     nfolds=nrow(train_mtx),\n                                     grouped=FALSE,\n                                     alpha=0.5, # elastic net\n                                     type.measure=\"mae\", # not sure whether this is better\n                                     standardize=TRUE, # by default each feature is standardized internally\n                                     family=\"gaussian\"\n                                     )\n          lambda_value &lt;- ifelse(model$lambda.min==model$lambda[1], \n                                 model$lambda[2], model$lambda.min)\n          predictions &lt;- predict(model,\n                                 newx=test_mtx, \n                                 s=lambda_value)[,1]\n        }\n        else {\n          stop(paste0(model_name), \" not implemented\")\n        }\n        \n        tibble::tibble(task=task$name,\n                       trainset = paste0(train_dataset, collapse=\"__\"),\n                       testset = test_dataset,\n                       test_subset = test_df_with_subject$subject_id,\n                       target = test_df$target, \n                       prediction = predictions,\n                       testset_mean = mean(test_df$target),\n                       model = model_name,\n                       feature_set = feature_name)\n      }) %&gt;%\n        dplyr::bind_rows()\n      result_list &lt;- rlist::list.append(result_list, cross_dataset_out)\n    }\n  }\n}\n\n\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\n\n\nWarning: from glmnet C++ code (error code -95); Convergence for 95th lambda\nvalue not reached after maxit=100000 iterations; solutions for larger lambdas\nreturned\n\n\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\nWarning in addShadowsAndGetImp(decReg, runs): getImp result contains NA(s) or\nNaN(s); replacing with 0(s), yet this is suspicious.\n\n\nCode\nresult_df &lt;- dplyr::bind_rows(result_list)\nresult_df\n\n\n\n  \n\n\n\nCode\ntictoc::toc()\n\n\n11317.668 sec elapsed\n\n\n\n\nCode\nresult_summary &lt;- result_df %&gt;%\n    dplyr::group_by(task, feature_set, model, trainset, testset) %&gt;%\n    dplyr::summarise(\n      test_mse = get_mse(target, prediction),\n      test_r2 = get_r2(target, prediction),\n      test_srho = get_spearman(target, prediction),\n      mse_same_cohort = get_mse(target, testset_mean),\n      .groups = \"drop\"\n    )\n\n\nWarning: There were 141 warnings in `dplyr::summarise()`.\nThe first warning was:\ni In argument: `test_srho = get_spearman(target, prediction)`.\ni In group 10: `task = \"task_11\"`, `feature_set = \"metadata\"`, `model =\n  \"rf+boruta\"`, `trainset = \"2022_dataset\"`, `testset = \"2021_dataset\"`.\nCaused by warning in `cor()`:\n! the standard deviation is zero\ni Run `dplyr::last_dplyr_warnings()` to see the 140 remaining warnings.\n\n\nCode\nresult_summary\n\n\n\n  \n\n\n\nWhy is that? This happens when the boruta algorithm returns 0 important features, which means in the test set the predictions are set to some constant. And since a constant vector has 0 standard deviation, we cannot compute the correlation (where we divide by the standard deviation).\n\n\nCode\nresult_summary %&gt;%\n  dplyr::filter(is.na(test_srho)) %&gt;%\n  dplyr::count(task, model)\n\n\n\n  \n\n\n\n\n\nCode\nmodel_selection_df &lt;- result_summary %&gt;%\n  dplyr::select(task, feature_set, model, testset, test_srho) %&gt;%\n  tidyr::pivot_wider(values_from=test_srho, names_from=testset) %&gt;%\n  dplyr::mutate(srho_mean = apply(select(., matches(\"[0-9]+_dataset\")), 1, mean, na.rm=TRUE)) %&gt;%\n  dplyr::filter(!is.na(srho_mean)) %&gt;% # so we only keep entries where predictions in all test sets where constant\n  dplyr::mutate(srho_min = apply(select(., matches(\"[0-9]+_dataset\")), 1, min, na.rm=TRUE)) %&gt;%\n  dplyr::mutate(srho_sd = apply(select(., matches(\"[0-9]+_dataset\")), 1, sd, na.rm=TRUE)) %&gt;%\n  dplyr::mutate(srho_mean = round(srho_mean, 3)) %&gt;%\n  dplyr::mutate(srho_min = round(srho_min, 3)) %&gt;%\n  dplyr::mutate(srho_sd = round(srho_sd, 3)) %&gt;%\n  dplyr::mutate(across(matches(\"[0-9]+_dataset\"), ~ round(.x, 3))) %&gt;%\n  dplyr::mutate(dim_red = dplyr::case_when(\n    str_detect(feature_set, \"_pca\") ~ \"pca\",\n    TRUE ~ \"none\"\n  )) %&gt;%\n  dplyr::mutate(n_modalities = (stringr::str_count(feature_set, \"\\\\+\") + 1)) %&gt;%\n  dplyr::select(task, model, srho_mean, srho_sd, srho_min, !feature_set, feature_set)\n\n\n\n\nCode\nreadr::write_delim(model_selection_df, file=file.path(output_dir, \"model_selection_df.tsv\"), delim=\"\\t\")\n#model_selection_df &lt;- readr::read_delim(file.path(output_dir, \"model_selection_df.tsv\"), delim=\"\\t\")\n\nlibrary(openxlsx)\n# see https://ycphs.github.io/openxlsx/reference/openxlsx_options.html\n#base::options()\nwb &lt;- openxlsx::createWorkbook()\nopenxlsx::addWorksheet(wb, \"results_unfiltered\")\nopenxlsx::setColWidths(wb, sheet=\"results_unfiltered\", cols = 1:10, widths = 15)\nopenxlsx::setColWidths(wb, sheet=\"results_unfiltered\", cols = 11:12, widths = 100)\nopenxlsx::writeDataTable(wb, \n                         sheet = \"results_unfiltered\", \n                         x = model_selection_df, \n                         startRow = 1, \n                         startCol = 1,\n                         tableStyle = \"TableStyleDark1\")\n\nfor (task in unique(model_selection_df$task)) {\n  # task &lt;- \"task_21\"\n  task_result_df &lt;- model_selection_df %&gt;%\n    dplyr::filter(task == !!task) %&gt;%\n    dplyr::filter(!is.na(srho_sd)) %&gt;%\n    dplyr::arrange(desc(srho_mean)) \n  openxlsx::addWorksheet(wb, task)\n  openxlsx::setColWidths(wb, sheet=task, cols = 1:10, widths = 15)\n  openxlsx::setColWidths(wb, sheet=task, cols = 11:12, widths = 100)\n  openxlsx::writeDataTable(wb, \n                         sheet = task,\n                         x = task_result_df, \n                         startRow = 1, \n                         startCol = 1,\n                         tableStyle = \"TableStyleDark1\")\n}\nopenxlsx::saveWorkbook(wb, file=file.path(output_dir, \"model_selection_df.xlsx\"), overwrite = TRUE)\n\n\n\n\n8 Prediction for 2023\n\nLoad the submission template\n\n\n\nCode\nsubmission_df &lt;- readr::read_tsv(file.path(input_dir, \"3rdChallengeSubmissionTemplate_10032024.tsv\"),\n                                 show_col_types = FALSE)\nsubmission_df\n\n\n\n  \n\n\n\nCheck which assays are missing most often\n\n\nCode\ntest_assays_available &lt;- submission_df %&gt;%\n  dplyr::select(SubjectID) %&gt;%\n  tidylog::left_join(meta_data_plus_assays_day_0, by=c(\"SubjectID\"=\"subject_id\"))\n\n\nleft_join: added 21 columns (specimen_id, actual_day_relative_to_boost, planned_day_relative_to_boost, visit, infancy_vac, ...)\n           &gt; rows only in x                           0\n           &gt; rows only in meta_data_plus_assays_d.. (98)\n           &gt; matched rows                            54\n           &gt;                                        ====\n           &gt; rows total                              54\n\n\n\n\nCode\ncolMeans(test_assays_available[, names(experimental_predictors_day_0)]) %&gt;% sort()\n\n\n     plasma_cytokine_concentration_by_olink \n                                  0.5925926 \n                        pbmc_cell_frequency \n                                  0.8888889 \n                        t_cell_polarization \n                                  0.9444444 \n                          t_cell_activation \n                                  0.9629630 \n                       pbmc_gene_expression \n                                  0.9814815 \n                            plasma_ab_titer \n                                  1.0000000 \nplasma_cytokine_concentration_by_legendplex \n                                  1.0000000 \n\n\n\n\nCode\nrowSums(test_assays_available[, names(experimental_predictors_day_0)]) %&gt;% sort()\n\n\n [1] 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7\n[39] 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n\n\n\nDefine for each task a list with the following entries\n\n\n\nCode\ncolnames(submission_df)\n\n\n [1] \"SubjectID\"                           \"Age\"                                \n [3] \"BiologicalSexAtBirth\"                \"VaccinePrimingStatus\"               \n [5] \"1.1) IgG-PT-D14-titer-Rank\"          \"1.2) IgG-PT-D14-FC-Rank\"            \n [7] \"2.1) Monocytes-D1-Rank\"              \"2.2) Monocytes-D1-FC-Rank\"          \n [9] \"3.1) CCL3-D3-Rank\"                   \"3.2) CCL3-D3-FC-Rank\"               \n[11] \"4.1) IFNG/IL5-Polarization-D30-Rank\"\n\n\n\n\nCode\nprediction_specs &lt;- list(\n  \"task_11\" = list(\n    \"model\" = \"lasso\",\n    \"feature_set\" = \"plasma_cytokine_concentration_by_legendplex_pca+metadata+baseline\",\n    \"table_col\" = \"1.1) IgG-PT-D14-titer-Rank\"\n  ),\n  \"task_12\" = list(\n    \"model\" = \"lasso\",\n    \"feature_set\" = \"pbmc_cell_frequency+pbmc_gene_expression+t_cell_activation+t_cell_polarization+metadata+baseline\",\n    \"table_col\" = \"1.2) IgG-PT-D14-FC-Rank\"\n  ),\n  \"task_21\" = list(\n    \"model\" = \"rf\",\n    \"feature_set\" = \"pbmc_cell_frequency_pca+plasma_cytokine_concentration_by_legendplex_pca+t_cell_activation_pca+metadata+baseline\",\n    \"table_col\" = \"2.1) Monocytes-D1-Rank\"\n  ),\n  \"task_22\" = list(\n    \"model\" = \"elnet\",\n    \"feature_set\" = \"pbmc_cell_frequency+plasma_cytokine_concentration_by_legendplex+metadata+baseline\",\n    \"table_col\" = \"2.2) Monocytes-D1-FC-Rank\"\n  ),\n  \"task_31\" = list(\n    \"model\" = \"lasso\",\n    \"feature_set\" = \"plasma_cytokine_concentration_by_legendplex+metadata+baseline\",\n    \"table_col\" = \"3.1) CCL3-D3-Rank\"\n  ),\n  \"task_32\" = list(\n    \"model\" = \"rf\",\n    \"feature_set\" = \"pbmc_cell_frequency+pbmc_gene_expression+plasma_ab_titer+plasma_cytokine_concentration_by_legendplex+t_cell_activation+t_cell_polarization+metadata+baseline\",\n    \"table_col\" = \"3.2) CCL3-D3-FC-Rank\"\n  ),\n  \"task_41\" = list(\n    \"model\" = \"elnet\",\n    \"feature_set\" = \"pbmc_cell_frequency+pbmc_gene_expression+t_cell_activation+metadata+baseline\",\n    \"table_col\" = \"4.1) IFNG/IL5-Polarization-D30-Rank\"\n  )\n)\n\n# checks\n## 0) all task column names are in submission table\npurrr::map_lgl(prediction_specs, ~ .x[[\"table_col\"]] %in% colnames(submission_df)) %&gt;%\n  all() %&gt;%\n  stopifnot()\n\n## a) all tasks are specified\nstopifnot(dplyr::setequal(names(task_meta), names(prediction_specs)))\n\n## b) all features are present\npurrr::map_lgl(prediction_specs, ~ length(str_split(.x[[\"feature_set\"]], \"\\\\+\")[[1]]) &gt; 2) %&gt;%\n  all() %&gt;%\n  stopifnot()\n\npurrr::map_lgl(prediction_specs, ~ .x[[\"feature_set\"]] %in% names(feature_list)) %&gt;%\n  all() %&gt;%\n  stopifnot()\n\n## c) which features are never selected?\nselected_features &lt;- purrr::map(prediction_specs, ~ str_split(.x[[\"feature_set\"]], \"\\\\+\")[[1]]) %&gt;%\n  unlist() %&gt;%\n  unique()\n\nall_features &lt;- purrr::map(names(feature_list), ~ str_split(.x, \"\\\\+\")[[1]]) %&gt;%\n  unlist() %&gt;%\n  unique()\n\nall_features[!all_features %in% selected_features]\n\n\n[1] \"pbmc_gene_expression_pca\"                  \n[2] \"plasma_ab_titer_pca\"                       \n[3] \"plasma_cytokine_concentration_by_olink_pca\"\n[4] \"t_cell_polarization_pca\"                   \n[5] \"plasma_cytokine_concentration_by_olink\"    \n\n\nCode\nrm(selected_features, all_features)\n\n## d) which features are most commonly used\npurrr::map(prediction_specs, ~ str_split(.x[[\"feature_set\"]], \"\\\\+\")[[1]]) %&gt;%\n  unlist() %&gt;%\n  stringr::str_remove_all(., \"_pca$\") %&gt;%\n  table() %&gt;%\n  sort(decreasing=TRUE)\n\n\n.\n                                   baseline \n                                          7 \n                                   metadata \n                                          7 \n                        pbmc_cell_frequency \n                                          5 \nplasma_cytokine_concentration_by_legendplex \n                                          5 \n                          t_cell_activation \n                                          4 \n                       pbmc_gene_expression \n                                          3 \n                        t_cell_polarization \n                                          2 \n                            plasma_ab_titer \n                                          1 \n\n\nCode\n## e) all models are implemented\npurrr::map_lgl(prediction_specs, ~ .x[[\"model\"]] %in% c(\"rf\", \"rf+boruta\", \"elnet\", \"lasso\")) %&gt;%\n  all() %&gt;%\n  stopifnot()\n\n## f) pull scores from result df\npurrr::imap(prediction_specs, function(task_specs, task) {\n  entry &lt;- model_selection_df %&gt;%\n    dplyr::filter(task == !!task) %&gt;%\n    dplyr::filter(model == !!task_specs[[\"model\"]]) %&gt;%\n    dplyr::filter(feature_set == !!task_specs[[\"feature_set\"]])\n  stopifnot(nrow(entry)==1)\n  return(entry)\n}) %&gt;%\n  dplyr::bind_rows()\n\n\n\n  \n\n\n\n\nMake the predictions\n\n\nTrain model on full dataset\nMake predictions for the 2023 data\n\n\n\nCode\npredictions_list &lt;- list()\n\ntask_name &lt;- \"task_41\"\n\nfor (task_name in names(prediction_specs)) {\n  task_specs &lt;- prediction_specs[[task_name]]\n  \n  print(task_name)\n  print(task_specs$model)\n  print(task_specs$feature_set)\n  \n  task_df &lt;- target_list[[task_name]]\n    \n  target_df &lt;- task_df %&gt;%\n    dplyr::select(subject_id, target)\n  \n  baseline_df &lt;- baseline_list[[task_name]]\n  \n  feature_df &lt;- feature_list[[task_specs$feature_set]]\n  \n  if (str_detect(task_specs$feature_set, \"baseline\")) {\n    feature_df &lt;- feature_df %&gt;%\n      dplyr::left_join(baseline_df, by=\"subject_id\")\n  }\n  \n  train_df &lt;- target_df %&gt;%\n    tidylog::inner_join(feature_df, by=\"subject_id\") %&gt;%\n    dplyr::left_join(dplyr::distinct(dplyr::select(meta_data, c(subject_id, dataset))),\n                     by=\"subject_id\") %&gt;%\n    dplyr::select(-c(dataset)) %&gt;%\n    tibble::column_to_rownames(var=\"subject_id\")\n  stopifnot(!any(is.na(train_df)))\n  stopifnot(nrow(train_df)==nrow(dplyr::distinct(train_df)))\n  # check that features were duplicated during joining of tables (i.e. features end with .x and .y) -&gt; but doesn't make sense with the PCA joining...\n  #stopifnot(all(purrr::map_dbl(stringr::str_split(colnames(train_df), \"\\\\.\"), ~ length(.x)) == 1))\n  #colnames(train_df)[purrr::map_dbl(stringr::str_split(colnames(train_df), \"\\\\.\"), ~ length(.x)) &gt; 1]\n  \n  test_df &lt;- submission_df %&gt;%\n    dplyr::mutate(subject_id = SubjectID) %&gt;% \n    dplyr::select(subject_id) %&gt;%\n    dplyr::left_join(feature_df, by=\"subject_id\") %&gt;%\n    tibble::column_to_rownames(var=\"subject_id\")\n  \n  # check if the baseline is missing for certain instances\n  if (str_detect(task_specs$feature_set, \"baseline\")) {\n    if (sum(is.na(test_df$baseline)) &gt; 0) {\n      message(paste0(\"Baseline values are missing for \", \n                   sum(is.na(test_df$baseline)),\n                   \" samples! Imputing with Median\"))\n      test_df$baseline[is.na(test_df$baseline)] &lt;- median(test_df$baseline, na.rm=TRUE)\n    }\n  }\n  \n  # now there should be no more NAs!\n  stopifnot(mean(is.na(test_df)) == 0)\n  \n  # some more checks\n  stopifnot(identical(colnames(train_df)[colnames(train_df)!=\"target\"], colnames(test_df)))\n  #colnames(test_df)[!colnames(test_df) %in% colnames(train_df)]\n  #colnames(train_df)[!colnames(train_df) %in% colnames(test_df)]\n  \n  # if we need matrix, vector objects for certain ML algos\n  train_mtx &lt;- as.matrix(dplyr::select(train_df, -target))\n  train_target &lt;- dplyr::pull(train_df, target)\n  test_mtx &lt;- as.matrix(test_df)\n  \n  if (task_specs$model == \"rf\") {\n    model &lt;- ranger::ranger(formula = target ~ ., \n                            data = train_df, \n                            num.trees = 500)\n    predictions &lt;- predict(model, test_df)$predictions\n    names(predictions) &lt;- rownames(test_df)\n  } else if (task_specs$model == \"rf+boruta\") {\n    boruta_out &lt;- Boruta::Boruta(formula = target ~ .,\n                                 data = train_df,\n                                 maxRuns=1000,\n                                 num.trees=500 \n                                 )\n    boruta_feats &lt;- names(boruta_out$finalDecision)[boruta_out$finalDecision==\"Confirmed\"]\n    stopifnot(length(boruta_feats) != 0)\n  \n    train_df_subset &lt;- train_df %&gt;% dplyr::select(dplyr::all_of(c(boruta_feats, \"target\")))\n    test_df_subset &lt;- test_df %&gt;% dplyr::select(dplyr::all_of(c(boruta_feats, \"target\")))\n    model &lt;- ranger::ranger(formula = target ~ ., \n                            data = train_df_subset, \n                            num.trees = 500)\n    predictions &lt;- predict(model, test_df_subset)$predictions\n  } else if (task_specs$model == \"lasso\") {\n    # standardize the features, even though glmnet is doing this automatically!\n    feature_means &lt;- matrixStats::colMeans2(train_mtx)\n    feature_sds &lt;- matrixStats::colSds(train_mtx)\n    train_mtx &lt;- t((t(train_mtx) - feature_means) / feature_sds)\n    train_target &lt;- (train_target - mean(train_target)) / sd(train_target)\n    #test_mtx &lt;- t((t(test_mtx) - feature_means) / feature_sds)\n    \n    # inner hyperparameter optim loop using LOOCV to find best lambda\n    model &lt;- glmnet::cv.glmnet(x=train_mtx,\n                               y=train_target,\n                               nfolds=nrow(train_mtx),\n                               grouped=FALSE,\n                               alpha=1, # LASSO\n                               type.measure=\"mae\", # not sure whether this is better\n                               standardize=TRUE, # by default each feature is standardized internally\n                               family=\"gaussian\"\n                               )\n    # investigate\n    #beta_mtx &lt;- as.data.frame(as.matrix(model$glmnet.fit$beta))\n    #colnames(beta_mtx) &lt;- paste0(\"lambda_\", round(model$lambda, 3))\n    #plot(model)\n    #lambda_value &lt;- model$lambda.1se, # model$lambda.min\n    # never use zero features (with lamba=model$lambda[1]), since constant predictions\n    # will have NA spearman...\n    lambda_value &lt;- ifelse(model$lambda.min==model$lambda[1], \n                           model$lambda[2], model$lambda.min)\n    predictions &lt;- predict(model,\n                           newx=test_mtx, \n                           s=lambda_value)[,1]\n  } else if (task_specs$model == \"elnet\") {\n    # standardize the features, even though glmnet is doing this automatically!\n    feature_means &lt;- matrixStats::colMeans2(train_mtx)\n    feature_sds &lt;- matrixStats::colSds(train_mtx)\n    train_mtx &lt;- t((t(train_mtx) - feature_means) / feature_sds)\n    train_target &lt;- (train_target - mean(train_target)) / sd(train_target)\n    #test_mtx &lt;- t((t(test_mtx) - feature_means) / feature_sds)\n    \n    # inner hyperparameter optim loop using LOOCV to find best lambda\n    model &lt;- glmnet::cv.glmnet(x=train_mtx,\n                               y=train_target,\n                               nfolds=nrow(train_mtx),\n                               grouped=FALSE,\n                               alpha=0.5, # elastic net\n                               type.measure=\"mae\", # not sure whether this is better\n                               standardize=TRUE, # by default each feature is standardized internally\n                               family=\"gaussian\"\n                               )\n    lambda_value &lt;- ifelse(model$lambda.min==model$lambda[1], \n                           model$lambda[2], model$lambda.min)\n    predictions &lt;- predict(model,\n                           newx=test_mtx, \n                           s=lambda_value)[,1]\n  }\n  \n  stopifnot(all(names(predictions) == rownames(test_df)))\n  \n  predictions_list[[task_name]] &lt;- \n    tibble::tibble(subject_id = as.numeric(names(predictions)), \n                   predictions = predictions,\n                   task_name = task_name,\n                   model = task_specs$model,\n                   feature_set = task_specs$feature_set)\n}\n\n\n[1] \"task_11\"\n[1] \"lasso\"\n[1] \"plasma_cytokine_concentration_by_legendplex_pca+metadata+baseline\"\n\n\ninner_join: added 11 columns (PC1, PC2, PC3, PC4, PC5, ...)\n            &gt; rows only in x          ( 4)\n            &gt; rows only in feature_df (54)\n            &gt; matched rows             49\n            &gt;                         ====\n            &gt; rows total               49\n\n\n[1] \"task_12\"\n[1] \"lasso\"\n[1] \"pbmc_cell_frequency+pbmc_gene_expression+t_cell_activation+t_cell_polarization+metadata+baseline\"\n\n\ninner_join: added 2,024 columns (pbmc_cell_frequency_Basophils, pbmc_cell_frequency_Bcells, pbmc_cell_frequency_CD4Tcells, pbmc_cell_frequency_CD8Tcells, pbmc_cell_frequency_Classical_Monocytes, ...)\n            &gt; rows only in x          ( 1)\n            &gt; rows only in feature_df (56)\n            &gt; matched rows             52\n            &gt;                         ====\n            &gt; rows total               52\n\n\n[1] \"task_21\"\n[1] \"rf\"\n[1] \"pbmc_cell_frequency_pca+plasma_cytokine_concentration_by_legendplex_pca+t_cell_activation_pca+metadata+baseline\"\n\n\ninner_join: added 20 columns (PC1.x, PC2.x, PC3.x, PC4.x, PC5.x, ...)\n            &gt; rows only in x          (15)\n            &gt; rows only in feature_df (57)\n            &gt; matched rows             51\n            &gt;                         ====\n            &gt; rows total               51\nBaseline values are missing for 6 samples! Imputing with Median\n\n\n[1] \"task_22\"\n[1] \"elnet\"\n[1] \"pbmc_cell_frequency+plasma_cytokine_concentration_by_legendplex+metadata+baseline\"\n\n\ninner_join: added 28 columns (pbmc_cell_frequency_Basophils, pbmc_cell_frequency_Bcells, pbmc_cell_frequency_CD4Tcells, pbmc_cell_frequency_CD8Tcells, pbmc_cell_frequency_Classical_Monocytes, ...)\n            &gt; rows only in x          ( 0)\n            &gt; rows only in feature_df (57)\n            &gt; matched rows             66\n            &gt;                         ====\n            &gt; rows total               66\nBaseline values are missing for 6 samples! Imputing with Median\n\n\n[1] \"task_31\"\n[1] \"lasso\"\n[1] \"plasma_cytokine_concentration_by_legendplex+metadata+baseline\"\n\n\ninner_join: added 18 columns (plasma_cytokine_concentration_by_legendplex_P01375, plasma_cytokine_concentration_by_legendplex_P01563, plasma_cytokine_concentration_by_legendplex_P01579, plasma_cytokine_concentration_by_legendplex_P02778, plasma_cytokine_concentration_by_legendplex_P05231, ...)\n            &gt; rows only in x          (34)\n            &gt; rows only in feature_df (54)\n            &gt; matched rows             49\n            &gt;                         ====\n            &gt; rows total               49\nBaseline values are missing for 1 samples! Imputing with Median\n\n\n[1] \"task_32\"\n[1] \"rf\"\n[1] \"pbmc_cell_frequency+pbmc_gene_expression+plasma_ab_titer+plasma_cytokine_concentration_by_legendplex+t_cell_activation+t_cell_polarization+metadata+baseline\"\n\n\ninner_join: added 2,073 columns (pbmc_cell_frequency_Basophils, pbmc_cell_frequency_Bcells, pbmc_cell_frequency_CD4Tcells, pbmc_cell_frequency_CD8Tcells, pbmc_cell_frequency_Classical_Monocytes, ...)\n            &gt; rows only in x          (32)\n            &gt; rows only in feature_df (54)\n            &gt; matched rows             51\n            &gt;                         ====\n            &gt; rows total               51\nBaseline values are missing for 1 samples! Imputing with Median\n\n\n[1] \"task_41\"\n[1] \"elnet\"\n[1] \"pbmc_cell_frequency+pbmc_gene_expression+t_cell_activation+metadata+baseline\"\n\n\ninner_join: added 2,018 columns (pbmc_cell_frequency_Basophils, pbmc_cell_frequency_Bcells, pbmc_cell_frequency_CD4Tcells, pbmc_cell_frequency_CD8Tcells, pbmc_cell_frequency_Classical_Monocytes, ...)\n            &gt; rows only in x          ( 0)\n            &gt; rows only in feature_df (79)\n            &gt; matched rows             43\n            &gt;                         ====\n            &gt; rows total               43\nBaseline values are missing for 3 samples! Imputing with Median\n\n\n\n\nCode\nnames(predictions_list)\n\n\n[1] \"task_11\" \"task_12\" \"task_21\" \"task_22\" \"task_31\" \"task_32\" \"task_41\"\n\n\n\n\nCode\nsubmission_df_with_predictions &lt;- submission_df\n\nfor (task_name in names(predictions_list)) {\n  task_preds_df &lt;- predictions_list[[task_name]] %&gt;%\n    dplyr::select(subject_id, predictions)\n  \n  submission_df_with_predictions &lt;- submission_df_with_predictions %&gt;%\n    tidylog::left_join(task_preds_df, by=c(\"SubjectID\" = \"subject_id\")) %&gt;%\n    dplyr::mutate(!!prediction_specs[[task_name]][[\"table_col\"]] := predictions) %&gt;%\n    dplyr::select(-predictions)\n}\n\n\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\nleft_join: added one column (predictions)\n           &gt; rows only in x               0\n           &gt; rows only in task_preds_df ( 0)\n           &gt; matched rows                54\n           &gt;                            ====\n           &gt; rows total                  54\n\n\nCode\nsubmission_df_with_predictions\n\n\n\n  \n\n\n\nLastly we need to create ranks from those predictions, see:\n\nhttps://discuss.cmi-pb.org/t/ranking-results-clarification/321\nWe expect contestants to generate computational models, and upon making predictions, these values are ranked from highest to lowest (i.e.highest = 1, lowest = N) before making a final submission.\n\n\n\nCode\nsubmission_df_with_rank &lt;- submission_df_with_predictions\n\ntask_titles &lt;- purrr::map_chr(prediction_specs, ~ .x[[\"table_col\"]])\nstopifnot(all(task_titles %in% colnames(submission_df_with_predictions)))\n\nfor (task_title_oi in task_titles) {\n  submission_df_with_rank[[task_title_oi]] &lt;- \n    rank(submission_df_with_predictions[[task_title_oi]], ties.method=\"average\")\n}\nreadr::write_tsv(\n  x = submission_df_with_rank, \n  file = file.path(output_dir, paste0(format(Sys.Date(), \"%Y-%m-%d\"), \"_submission_psls.tsv\"))\n)\nsubmission_df_with_rank\n\n\n\n  \n\n\n\n\n\n9 Appendix\nAlso write the image just in case\n\n\nCode\nsave.image(file=file.path(output_dir, paste0(format(Sys.Date(), \"%Y-%m-%d\"), \"_model_selection_session.RData\")))\n#load(file=file.path(output_dir, \"model_selection_session.RData\"))"
  },
  {
    "objectID": "eda/raw_data_overview.html",
    "href": "eda/raw_data_overview.html",
    "title": "Data Overview",
    "section": "",
    "text": "Code\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(ggdark)\n  library(factoextra)\n  library(FactoMineR)\n  library(magick)\n  library(ComplexHeatmap)\n  library(circlize)\n})\n\nsource(file.path(\"..\", \"src\", \"read_data.R\"))\nsource(file.path(\"..\", \"src\", \"colors.R\"))"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-many-subjects-do-we-have-per-dataset-per-partition",
    "href": "eda/raw_data_overview.html#how-many-subjects-do-we-have-per-dataset-per-partition",
    "title": "Data Overview",
    "section": "4.1 How many subjects do we have per dataset / per partition?",
    "text": "4.1 How many subjects do we have per dataset / per partition?\n\n\nCode\nmeta_data %&gt;%\n  dplyr::select(subject_id, dataset, partition, infancy_vac) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::count(dataset, partition, infancy_vac) %&gt;%\n  ggplot(aes(x = n, y = dataset, fill = infancy_vac, color = partition)) +\n  geom_col(position = position_dodge(width = 0.9), width = 0.7, alpha=0.5) +  \n  geom_text(aes(label = n), \n            position = position_dodge(width = 0.9),  \n            hjust = -0.2, vjust = 0.5, size = 3, color = \"white\") +\n  scale_fill_manual(values = infancy_vac_colors) +\n  scale_color_manual(values = partition_colors) +\n  ggdark::dark_mode(verbose = FALSE)"
  },
  {
    "objectID": "eda/raw_data_overview.html#what-is-the-age-range",
    "href": "eda/raw_data_overview.html#what-is-the-age-range",
    "title": "Data Overview",
    "section": "4.2 What is the age range",
    "text": "4.2 What is the age range\n\n\nCode\np1 &lt;- meta_data %&gt;%\n  ggplot() + \n  geom_histogram(aes(x=age_at_boost, fill=dataset, y=after_stat(density)), \n                 color=\"black\", position=\"identity\", bins=30, show.legend=FALSE) +\n  facet_wrap(~dataset) +\n  scale_fill_manual(values=dataset_colors) +\n  ggdark::dark_mode(verbose=FALSE)\n\np2 &lt;- meta_data %&gt;%\n  ggplot() +\n  geom_violin(aes(y=dataset, x=age_at_boost, fill=dataset)) +\n  ggdark::dark_mode(verbose=FALSE) +\n  scale_fill_manual(values=dataset_colors)\n\ncowplot::plot_grid(p1, p2, ncol=2, rel_widths=c(1.5,1))"
  },
  {
    "objectID": "eda/raw_data_overview.html#what-is-the-difference-between-planned-and-actual-booster-administration",
    "href": "eda/raw_data_overview.html#what-is-the-difference-between-planned-and-actual-booster-administration",
    "title": "Data Overview",
    "section": "5.1 What is the difference between planned and actual booster administration",
    "text": "5.1 What is the difference between planned and actual booster administration\n\n\nCode\nmeta_data %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=diff_relative_to_boost), binwidth=1) +\n  facet_wrap(~dataset) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/raw_data_overview.html#what-is-the-difference-between-planned-and-actual-for-the-baseline",
    "href": "eda/raw_data_overview.html#what-is-the-difference-between-planned-and-actual-for-the-baseline",
    "title": "Data Overview",
    "section": "5.2 What is the difference between planned and actual for the baseline",
    "text": "5.2 What is the difference between planned and actual for the baseline\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==0) %&gt;%\n  dplyr::mutate(`diff_&gt;_15` = abs(actual_day_relative_to_boost) &gt; 15) %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=actual_day_relative_to_boost, fill=`diff_&gt;_15`), binwidth=1) +\n  facet_wrap(~dataset) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-many-time-points-do-we-have-per-subject",
    "href": "eda/raw_data_overview.html#how-many-time-points-do-we-have-per-subject",
    "title": "Data Overview",
    "section": "5.3 How many time points do we have per subject?",
    "text": "5.3 How many time points do we have per subject?\n\n\nCode\nmeta_data %&gt;%\n  dplyr::count(dataset, subject_id) %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=n, fill=dataset),color=\"black\", binwidth=1) +\n  facet_wrap(~dataset, ncol=2) +\n  ggdark::dark_mode(verbose=FALSE) +\n  scale_x_continuous(breaks=seq(0, 8, 1)) +\n  scale_fill_manual(values=dataset_colors)"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-many-assays-do-we-have-for-the-baseline-measurement",
    "href": "eda/raw_data_overview.html#how-many-assays-do-we-have-for-the-baseline-measurement",
    "title": "Data Overview",
    "section": "5.4 How many assays do we have for the baseline measurement?",
    "text": "5.4 How many assays do we have for the baseline measurement?\n\n\nCode\nassays_per_specimen &lt;- purrr::imap(exp_data, ~ .x %&gt;% \n              dplyr::select(specimen_id) %&gt;%\n              dplyr::distinct() %&gt;%\n              dplyr::mutate(assay=.y)) %&gt;%\n  dplyr::bind_rows() %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::select(specimen_id, assay, subject_id, planned_day_relative_to_boost, infancy_vac, dataset)\n\nassays_per_specimen %&gt;%\n  dplyr::count(subject_id, planned_day_relative_to_boost, dataset, specimen_id) %&gt;%\n  dplyr::filter(!is.na(subject_id)) %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==0) %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=n, fill=dataset), color=\"black\", binwidth=1) +\n  facet_wrap(~dataset, ncol=2) +\n  ggdark::dark_mode(verbose=FALSE) +\n  scale_x_continuous(breaks=seq(0, 8, 1)) +\n  scale_fill_manual(values=dataset_colors)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor (day in c(0, 1, 3, 14)) {\n  \nannotation_data &lt;- meta_data %&gt;%\n  dplyr::select(specimen_id, planned_day_relative_to_boost, infancy_vac, \n                dataset, biological_sex) %&gt;%\n  dplyr::filter(specimen_id %in% assays_per_specimen$specimen_id) %&gt;%\n  dplyr::filter(planned_day_relative_to_boost == !!day) %&gt;% \n  dplyr::select(- planned_day_relative_to_boost) %&gt;%\n  dplyr::arrange(dataset, infancy_vac, biological_sex) %&gt;%\n  tibble::column_to_rownames(\"specimen_id\") %&gt;%\n  dplyr::select(dataset, infancy_vac, biological_sex)\n\nheatmap_data &lt;- assays_per_specimen %&gt;%\n  dplyr::select(specimen_id, assay) %&gt;%\n  dplyr::mutate(value = 1) %&gt;%\n  tidyr::pivot_wider(names_from=\"assay\", values_from=\"value\") %&gt;%\n  mutate(across(everything(), .fns = ~replace_na(.,0))) %&gt;%\n  tibble::column_to_rownames(\"specimen_id\") %&gt;%\n  as.matrix() %&gt;%\n  t()\n\ncolnames(heatmap_data) &lt;- as.character(colnames(heatmap_data))\nheatmap_data &lt;- heatmap_data[, rownames(annotation_data)]\n\n# Create the heatmap\nht &lt;- Heatmap(heatmap_data, \n              name = \"heatmap\", \n              row_title = \"\", \n              column_title = paste0(\"Specimens for Planned Day \", day),\n              col = colorRamp2(c(0, 1), c(\"white\", \"black\")),\n              cluster_rows = FALSE,\n              cluster_columns = FALSE,\n              show_row_names = TRUE, \n              show_column_names = FALSE,\n              width = unit(16, \"cm\"),\n              top_annotation = ComplexHeatmap::HeatmapAnnotation(df = annotation_data,\n                                    col = list(\n                                      \"dataset\" = dataset_colors,\n                                      \"infancy_vac\" = infancy_vac_colors,\n                                      \"biological_sex\" = sex_colors\n                                    ),\n                                    which=\"column\")\n)\n\ndraw(ht, \n     heatmap_legend_side = \"top\",\n     annotation_legend_side = \"top\",\n     show_heatmap_legend = FALSE # don't show colorbar\n     )\n}"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-large-is-the-variance-in-the-baseline-measurements",
    "href": "eda/raw_data_overview.html#how-large-is-the-variance-in-the-baseline-measurements",
    "title": "Data Overview",
    "section": "5.5 How large is the variance in the baseline measurements?",
    "text": "5.5 How large is the variance in the baseline measurements?\n\n\nCode\nplot_time_course &lt;- function(experimental_data, modality) {\n  #experimental_data &lt;- exp_data; modality &lt;- \"pbmc_cell_frequency\"\n  \n  modality_settings &lt;- experimental_data_settings[[modality]]\n  feature_col &lt;- modality_settings$feature_col\n  value_col &lt;- modality_settings$value_col\n  \n  plot_df &lt;- experimental_data[[modality]] %&gt;%\n    dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n    dplyr::filter(planned_day_relative_to_boost &lt;= 0)\n  \n  # only keep datasets for which we have more than one time point\n  datasets_to_keep &lt;- plot_df %&gt;%\n    dplyr::select(dataset, planned_day_relative_to_boost) %&gt;%\n    dplyr::distinct() %&gt;%\n    dplyr::group_by(dataset) %&gt;%\n    dplyr::summarize(n = n()) %&gt;%\n    dplyr::filter(n &gt; 1) %&gt;%\n    dplyr::pull(dataset)\n  \n  plot_df &lt;- plot_df %&gt;%\n    dplyr::filter(dataset %in% datasets_to_keep)\n  \n  if (\"feature_subset\" %in% names(modality_settings)) {\n    plot_df &lt;- plot_df %&gt;% \n      dplyr::filter(.data[[feature_col]] %in% modality_settings$feature_subset)\n  }\n  plot_df &lt;- plot_df %&gt;%\n    dplyr::mutate(specimen_id = factor(specimen_id))\n  \n  # check for significant slopes?\n  pvals &lt;- purrr::map_dfr(unique(plot_df$dataset), function(d) {\n    purrr::map_dfr(unique(plot_df[[feature_col]]), function(f) {\n      # d=plot_df$dataset[1]; f=plot_df[[feature_col]][1]\n      model_df &lt;- plot_df %&gt;%\n        dplyr::filter(dataset==d, .data[[feature_col]]==f)\n      lin_model &lt;- lm(formula=paste0(value_col, \" ~ planned_day_relative_to_boost\"),\n         data = model_df)\n      tibble(dataset=d, feature=f, pval=summary(lin_model)$coefficients[2, 4])\n    })\n  }) %&gt;%\n    dplyr::mutate(padj = stats::p.adjust(pval))\n  pvals %&gt;%\n    dplyr::filter(padj &lt; 0.05) %&gt;%\n    print()\n  \n  p1 &lt;- plot_df %&gt;%\n    dplyr::group_by(subject_id, .data[[feature_col]]) %&gt;%\n    dplyr::summarize(min_feat = min(.data[[value_col]]),\n                     max_feat = max(.data[[value_col]]),\n                     mean_feat = mean(.data[[value_col]]),\n                     sd_feat = sd(.data[[value_col]]),\n                     .groups = \"drop\") %&gt;%\n    dplyr::mutate(cv = sd_feat / mean_feat) %&gt;%\n    ggplot() +\n    geom_violin(aes(y=.data[[feature_col]], x=cv)) +\n    ggdark::dark_mode() +\n    labs(x=\"Coefficient of Variation (CV)\")\n  \n  p2 &lt;- plot_df %&gt;%\n    ggplot(aes(x=planned_day_relative_to_boost, y=.data[[value_col]])) +\n    geom_point(aes(color=dataset), alpha=0.5) +\n    geom_line(aes(group=subject_id), alpha=0.5) +\n    facet_wrap(~.data[[feature_col]], scales=\"free_y\") +\n    geom_smooth(aes(color=dataset), method=\"lm\", formula = 'y ~ x') +\n    ggdark::dark_mode()\n  return(list(p1=p1, p2=p2))\n}\n\n\n\n\nCode\nplot_time_course(experimental_data=exp_data, modality=\"pbmc_cell_frequency\")\n\n\n# A tibble: 1 x 4\n  dataset      feature      pval   padj\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 2022_dataset Monocytes 0.00169 0.0338\n\n\n$p1\n\n\n\n\n\n\n\n\n\n\n$p2\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_time_course(experimental_data=exp_data, modality=\"plasma_ab_titer\")\n\n\n# A tibble: 0 x 4\n# i 4 variables: dataset &lt;chr&gt;, feature &lt;chr&gt;, pval &lt;dbl&gt;, padj &lt;dbl&gt;\n\n\n$p1\n\n\n\n\n\n\n\n\n\n\n$p2\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_time_course(experimental_data=exp_data, modality=\"plasma_cytokine_concentration_by_legendplex\")\n\n\n# A tibble: 0 x 4\n# i 4 variables: dataset &lt;chr&gt;, feature &lt;chr&gt;, pval &lt;dbl&gt;, padj &lt;dbl&gt;\n\n\n$p1\n\n\n\n\n\n\n\n\n\n\n$p2\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_time_course(experimental_data=exp_data, modality=\"plasma_cytokine_concentration_by_olink\")\n\n\n# A tibble: 0 x 4\n# i 4 variables: dataset &lt;chr&gt;, feature &lt;chr&gt;, pval &lt;dbl&gt;, padj &lt;dbl&gt;\n\n\n$p1\n\n\nWarning: Removed 65 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\n\n$p2\n\n\nWarning: Removed 67 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 67 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_time_course(experimental_data=exp_data, modality=\"t_cell_activation\")\n\n\n# A tibble: 0 x 4\n# i 4 variables: dataset &lt;chr&gt;, feature &lt;chr&gt;, pval &lt;dbl&gt;, padj &lt;dbl&gt;\n\n\n$p1\n\n\n\n\n\n\n\n\n\n\n$p2\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_time_course(experimental_data=exp_data, modality=\"t_cell_polarization\")\n\n\n# A tibble: 0 x 4\n# i 4 variables: dataset &lt;chr&gt;, feature &lt;chr&gt;, pval &lt;dbl&gt;, padj &lt;dbl&gt;\n\n\n$p1\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\n\n$p2"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-many-subjects-can-we-use-to-construct-training-data",
    "href": "eda/raw_data_overview.html#how-many-subjects-can-we-use-to-construct-training-data",
    "title": "Data Overview",
    "section": "6.1 How many subjects can we use to construct training data?",
    "text": "6.1 How many subjects can we use to construct training data?\n\n6.1.1 1) Antibody Level Tasks (anti-PT 14 days after booster)\n\nAll but 7 people were assayed approximately 14 days after the booster administration\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==14) %&gt;%\n  ggplot(aes(x=diff_relative_to_boost)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::select(subject_id, infancy_vac, dataset, biological_sex, ethnicity, race, year_of_birth) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::mutate(task_1_possible = \n                  subject_id %in% (meta_data %&gt;%\n                                     dplyr::filter(planned_day_relative_to_boost==14) %&gt;%\n                                     dplyr::left_join(exp_data$plasma_ab_titer,\n                                                      by=\"specimen_id\") %&gt;%\n                                     dplyr::filter(isotype_antigen==\"IgG_PT\") %&gt;%\n                                     tidyr::drop_na() %&gt;%\n                                     dplyr::pull(subject_id))\n  ) %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarise(task_1_possible_total = sum(task_1_possible), \n                   task_1_possible_fraction = mean(task_1_possible))\n\n\n\n  \n\n\n\n\n\n6.1.2 2) Cell Frequency Tasks (Monocytes 1 day after booster)\n\nBut there is one person where it does not really make sense\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==1) %&gt;%\n  ggplot(aes(x=diff_relative_to_boost)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::select(subject_id, infancy_vac, dataset, biological_sex, ethnicity, race, year_of_birth) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::mutate(task_possible = \n                  subject_id %in% (meta_data %&gt;%\n                                     dplyr::filter(planned_day_relative_to_boost==1) %&gt;%\n                                     dplyr::left_join(exp_data$pbmc_cell_frequency, by=\"specimen_id\") %&gt;%\n                                     dplyr::filter(cell_type_name==\"Monocytes\") %&gt;%\n                                     tidyr::drop_na() %&gt;%\n                                     dplyr::pull(subject_id))\n  ) %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarise(task_possible_total = sum(task_possible), \n                   task_possible_fraction = mean(task_possible))\n\n\n\n  \n\n\n\n\n\n6.1.3 3) Gene Expression Tasks (CCL3 expression 3 days after booster)\n\nThere are 7 people for which this task does nto make sense\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==3) %&gt;%\n  ggplot(aes(x=diff_relative_to_boost)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nall_genes &lt;- unique(exp_data$pbmc_gene_expression$versioned_ensembl_gene_id)\nccl3_ensembl &lt;- \"ENSG00000277632\"\nccl3_ensembl_versioned &lt;- all_genes[str_starts(all_genes, ccl3_ensembl)]\n\nmeta_data %&gt;%\n  dplyr::select(subject_id, infancy_vac, dataset, biological_sex, ethnicity, race, year_of_birth) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::mutate(task_possible = \n                  subject_id %in% (meta_data %&gt;%\n                                     dplyr::filter(planned_day_relative_to_boost==3) %&gt;%\n                                     dplyr::left_join(exp_data$pbmc_gene_expression, by=\"specimen_id\") %&gt;%\n                                     dplyr::filter(versioned_ensembl_gene_id==ccl3_ensembl_versioned) %&gt;%\n                                     tidyr::drop_na() %&gt;%\n                                     dplyr::pull(subject_id))\n  ) %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarise(task_possible_total = sum(task_possible), \n                   task_possible_fraction = mean(task_possible))"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-many-na-values-do-we-have-per-assay",
    "href": "eda/raw_data_overview.html#how-many-na-values-do-we-have-per-assay",
    "title": "Data Overview",
    "section": "7.1 How many NA values do we have per assay?",
    "text": "7.1 How many NA values do we have per assay?\n\n\nCode\npurrr::imap(exp_data, function(df, modality) {\n  feature_col &lt;- experimental_data_settings[[modality]]$feature_col\n  value_col &lt;- experimental_data_settings[[modality]]$value_col\n  tibble(modality = modality, feature_col = feature_col, sum_na = sum(is.na(df[[value_col]])))\n}) %&gt;%\n  dplyr::bind_rows()"
  },
  {
    "objectID": "eda/raw_data_overview.html#wide-format",
    "href": "eda/raw_data_overview.html#wide-format",
    "title": "Data Overview",
    "section": "7.2 Wide format",
    "text": "7.2 Wide format\n\n\nCode\npurrr::imap_dfr(generate_wide_experimental_data(experimental_data=exp_data, \n                                                impute=NULL),\n                  function(mtx, modality) {\n                    rmeans &lt;- rowMeans(is.na(mtx))\n                    tibble(modality=modality, \n                           subject_id = names(rmeans), \n                           na_frac=rmeans)\n           }) %&gt;%\n  dplyr::group_by(modality) %&gt;%\n  dplyr::summarise(mean_na_frac = mean(na_frac))\n\n\npbmc_cell_frequency | NA Fraction: 0.320140362330668 | Removed features: ASCs_(Plasmablasts), CD19_N_CD3_N_, CD19_P__CD3_N_, CD3_N_CD19_N_CD56_N_HLA_N_DR_P_CD14_N_CD16_N__cells, CD45_P_, CD56_P__CD3high_T_cells, Lineage_negative_cells_(CD3_N_CD19_N_CD56_N_HLA_N_DR_N_), TB_doublets, T_cells_(CD19_N_CD3_P_CD14_N_), CD33HLADR, CD3CD19, Tregs, mDC, MB_doublets_(CD19_P_CD14_P_), B_NK_doublets_(CD19_P_CD3_N_CD14_N_CD56_P_), T_M_doublets_(CD19_N_CD3_P_CD14_P_), Lineage__N__cells_(CD3_N_CD19_N_CD56_N_HLA_N_DR_N_), Antibody_secreting_B_cells_(ASCs), BNK_doublets, CD19_P_CD3_N_, CD3_N_CD19_N_, CD3_N_CD19_N_CD56_N_HLA_N_DR_N_CD14_N_CD16_N__cells, CD56_P_CD3high_T_cells, Lineage_N__cells_(CD3_N_CD19_N_CD56_N_HLA_N_DR_N_), MB_doublets, T_cells_(CD19_N_CD3_N_CD14_N_), TM_doublets\n\n\nWarning: Values from `MFI` are not uniquely identified; output will contain list-cols.\n* Use `values_fn = list` to suppress this warning.\n* Use `values_fn = {summary_fun}` to summarise duplicates.\n* Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(specimen_id, isotype_antigen)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\nplasma_cytokine_concentration_by_olink | NA Fraction: 0.700620342049714 | Removed features: Q969D9, Q96SB3, P16278, O75475, Q05516, Q9NWZ3, Q15661, P14317, Q9UHC6, Q6UXB4, Q00978, Q9UNE0, Q13574, Q8WTT0, P51617, Q9UMR7, Q06830, P30048, P09038, P30044, Q8N608, Q9C035, Q14203, P23229, Q15517, Q14435, Q96DB9, Q12933, P19474, Q8NHJ6, P34130, P08727, O43736, P50135, Q7Z6M3, Q9GZT9, Q12968, O60449, P63241, Q04637, P10747, Q03431, Q13490, P28845, P35240, Q9HCM2, Q9UQQ2, Q96P31, Q07065, P05412, O94992, Q8WXI8, Q04759, P16455, Q9NP99, P78310, P78362, Q13241, O14867, Q6ZUJ8, O43597, P52823, P27540, P58499, O60880, Q05084, O00273, Q96PD2, Q6DN72, O76036, P15514, Q8IU57, Q9UN19, Q9Y2J8, Q9Y3P8, P48740, Q9UQV4, Q9BXN2, Q6EIG7, O95786, P42701, Q92844, Q9UKX5, P52294, P18627, P05113, Q01151, P18564, P78410, Q07011, Q02763, P29965, P01583, Q9BZW8, Q15389, P49763, Q9Y653, O95727, P01732, Q16790, P01574, P00813, P01730, P29474, O00182, P35968, P25942, P20718, P49767, P01137, P09341, O43557, P01127, Q15116, P48023, Q14213,P29459, P09382, Q9NZQ7, P26842, P42830, P12544, P09601, P78423, P32970, Q9NP84, P55773, P06127, P09237, P07585, O75509, P43489, Q29983,Q29980, Q92583, P21246, Q14790, O75144, O43927, Q9BQ51, Q9HBE4, P78556, P10144, P29459,P29460, Q9H6B4, Q96JA1, O95502, P23526, P52888, P43234, Q96LA6, Q04900, P20711, Q9NPH0, Q03403, P25815, O15123, Q9Y5K6, O43827, Q9NY25, Q9GZM7, P35754, P09104, O95544, Q9UBU3, P50452, P35237, Q9HBB8, Q76M96, Q9NR28, Q8N1Q1, Q13275, O43240, Q9UKJ0, O95841, P51693, Q8IZP9, P19971, O75791, A6NI73, P00352, P40259, P09525, P50995, Q9Y286, P26010, P09417, O00161, P27695, O75356, Q9H4D0, P21964, Q15846, P51858, Q6WN34, P09668, Q15155, P16083, Q9BQB4, Q92520, Q8NBS9, P41236, Q9UHL4, Q86VZ4, Q9UHX3, Q6UWV6, Q8WTU2, Q8NI22, Q9BYZ8, Q8NBJ7, Q8WVQ1, P29017, P22466, P19022, Q06418, P46109, Q8WX77, Q9BZR6, P13611, P09467, P01222, P46379, Q92692, P05089, P40818, Q02790, P31431, Q9NWQ8, Q16773, P98082, Q9NQX5, Q641Q3, Q16820, Q01973, NT_N_proBNP, P12724\n\n\nplasma_cytokine_concentration_by_olink | NA Fraction: 0.700620342049714 | Removed samples: 760, 750, 903, 824, 894, 833\n\n\nt_cell_activation | NA Fraction: 0.0576923076923077 | Removed samples: 681\n\n\nt_cell_polarization | NA Fraction: 0.0165394402035623 | Removed samples: 1159, 529, 534, 643, 648"
  },
  {
    "objectID": "eda/raw_data_overview.html#what-is-the-fraction-of-na-values-in-the-pbmc-cell-type-frequencies",
    "href": "eda/raw_data_overview.html#what-is-the-fraction-of-na-values-in-the-pbmc-cell-type-frequencies",
    "title": "Data Overview",
    "section": "7.3 What is the fraction of NA values in the PBMC Cell Type Frequencies",
    "text": "7.3 What is the fraction of NA values in the PBMC Cell Type Frequencies\n\n7.3.1 Per Cell Type\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::mutate(is_na = is.na(percent_live_cell)) %&gt;%\n  dplyr::group_by(cell_type_name) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  dplyr::arrange(desc(frac_na)) %&gt;%\n  dplyr::mutate(cell_type_name = factor(cell_type_name, levels=rev(cell_type_name))) %&gt;%\n  ggplot() +\n  geom_col(aes(y=cell_type_name, x=frac_na)) +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Cell Type\")\n\n\n\n\n\n\n\n\n\n\n\n7.3.2 Per Specimen\nSo there are 5 specimen with more than 20% NA, which are all from the same subject!\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::mutate(is_na = is.na(percent_live_cell)) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  ggplot(aes(x = frac_na)) +\n  geom_histogram(bins = 20, color = \"white\", fill = \"blue\", alpha=0.1) +  # Add color for better visibility\n  stat_bin(aes(label = after_stat(count)), bins = 20, geom = \"text\", \n           vjust = -0.5, color = \"white\", size = 3) +  # Display bin counts at the top\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Specimen\")"
  },
  {
    "objectID": "eda/raw_data_overview.html#what-is-the-fraction-of-na-values-in-the-olink-data",
    "href": "eda/raw_data_overview.html#what-is-the-fraction-of-na-values-in-the-olink-data",
    "title": "Data Overview",
    "section": "7.4 What is the fraction of NA values in the Olink Data?",
    "text": "7.4 What is the fraction of NA values in the Olink Data?\n\n7.4.1 Per Protein\nAfter excluding Q969D9, the largest fraction of NA values is about 5% which is acceptable I guess.\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(is_na = is.na(concentration)) %&gt;%\n  dplyr::group_by(protein_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  dplyr::arrange(desc(frac_na)) %&gt;%\n  dplyr::mutate(protein_id = factor(protein_id, levels=rev(protein_id))) %&gt;%\n  ggplot() +\n  geom_col(aes(y=protein_id, x=frac_na)) +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Protein\")\n\n\n\n\n\n\n\n\n\n\n\n7.4.2 Per Specimen\nThere are 6 specimen with more than 50% NA values, I am not sure whether I should exclude those?\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(is_na = is.na(concentration)) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  ggplot(aes(x = frac_na)) +\n  geom_histogram(bins = 20, color = \"white\", fill = \"blue\", alpha=0.1) +  # Add color for better visibility\n  stat_bin(aes(label = after_stat(count)), bins = 20, geom = \"text\", \n           vjust = -0.5, color = \"white\", size = 3) +  # Display bin counts at the top\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Specimen\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(is_na = is.na(concentration)) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  dplyr::filter(frac_na &gt; 0.2) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::select(specimen_id, frac_na, subject_id, dataset, \n                actual_day_relative_to_boost, planned_day_relative_to_boost)"
  },
  {
    "objectID": "eda/raw_data_overview.html#plasma_ab_titer",
    "href": "eda/raw_data_overview.html#plasma_ab_titer",
    "title": "Data Overview",
    "section": "8.1 plasma_ab_titer",
    "text": "8.1 plasma_ab_titer\n\nSee also: https://discuss.cmi-pb.org/t/multiple-units-in-the-ab-titer-table/57/3\n\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::count(dataset, unit)"
  },
  {
    "objectID": "eda/raw_data_overview.html#plasma_cytokine_concentration_by_olink",
    "href": "eda/raw_data_overview.html#plasma_cytokine_concentration_by_olink",
    "title": "Data Overview",
    "section": "8.2 plasma_cytokine_concentration_by_olink",
    "text": "8.2 plasma_cytokine_concentration_by_olink\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::count(dataset, unit)"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-does-the-quality-control-for-olink-look-like",
    "href": "eda/raw_data_overview.html#how-does-the-quality-control-for-olink-look-like",
    "title": "Data Overview",
    "section": "9.1 How does the quality control for Olink look like?",
    "text": "9.1 How does the quality control for Olink look like?\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::count(quality_control)\n\n\n\n  \n\n\n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::count(partition, dataset)\n\n\n\n  \n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_legendplex %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::count(partition, dataset)"
  },
  {
    "objectID": "eda/raw_data_overview.html#how-often-is-the-cytokine-concentration-below-the-lod-in-olink",
    "href": "eda/raw_data_overview.html#how-often-is-the-cytokine-concentration-below-the-lod-in-olink",
    "title": "Data Overview",
    "section": "9.2 How often is the Cytokine Concentration below the LOD in Olink",
    "text": "9.2 How often is the Cytokine Concentration below the LOD in Olink\n\n\nCode\n# check how often is it below the limit of detection?\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(below_lod = concentration &lt; lower_limit_of_quantitation) %&gt;%\n  dplyr::count(below_lod)\n\n\n\n  \n\n\n\n\n\nCode\nset.seed(1)\np1 &lt;- exp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(below_lod = concentration &lt; lower_limit_of_quantitation) %&gt;%\n  dplyr::mutate(qc_warning = quality_control == \"Warning\") %&gt;%\n  dplyr::group_by(protein_id) %&gt;%\n  dplyr::summarize(mean_below_lod = mean(below_lod, na.rm=TRUE),\n                   mean_qc_warning = mean(qc_warning, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(cytokine_uniprot_mapping, by=\"protein_id\") %&gt;%\n  ggplot() +\n  geom_point(aes(x = mean_below_lod, y = mean_qc_warning)) +\n  ggrepel::geom_text_repel(aes(x = mean_below_lod, y = mean_qc_warning, \n                      label = ifelse(mean_below_lod &gt; 0.2, protein_id, '')),\n                  max.overlaps = Inf, color=\"grey\") + # This ensures all labels are shown\n  ggdark::dark_mode()\n\np2 &lt;- exp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(below_lod = concentration &lt; lower_limit_of_quantitation) %&gt;%\n  dplyr::mutate(qc_warning = quality_control == \"Warning\") %&gt;%\n  dplyr::group_by(protein_id) %&gt;%\n  dplyr::summarize(mean_below_lod = mean(below_lod, na.rm=TRUE),\n                   mean_qc_warning = mean(qc_warning, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(cytokine_uniprot_mapping, by=\"protein_id\") %&gt;%\n  ggplot() +\n  geom_point(aes(x = mean_below_lod, y = mean_qc_warning)) +\n  ggrepel::geom_text_repel(aes(x = mean_below_lod, y = mean_qc_warning, \n                      label = ifelse(mean_below_lod &gt; 0.2, cytokine, '')),\n                  max.overlaps = Inf, color=\"grey\") + # This ensures all labels are shown\n  ggdark::dark_mode()\n\ncowplot::plot_grid(p1, p2, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::filter(protein_id %in% c(\"P60568\"))\n\n\n\n  \n\n\n\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::mutate(below_lod = MFI &lt; lower_limit_of_detection) %&gt;%\n  dplyr::pull(below_lod) %&gt;%\n  mean(na.rm=TRUE)\n\n\n[1] 0.2994199"
  },
  {
    "objectID": "eda/raw_data_overview.html#what-is-the-fraction-of-antigen-specific-antibody-measurements",
    "href": "eda/raw_data_overview.html#what-is-the-fraction-of-antigen-specific-antibody-measurements",
    "title": "Data Overview",
    "section": "9.3 What is the fraction of antigen-specific antibody measurements",
    "text": "9.3 What is the fraction of antigen-specific antibody measurements\n\n9.3.1 Per Isotype-Antigen\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::group_by(isotype_antigen) %&gt;%\n  dplyr::summarize(is_antigen_specific_fraction = mean(is_antigen_specific)) %&gt;%\n  ggplot(aes(x=is_antigen_specific_fraction)) +\n  geom_histogram(bins=30, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), bins=30, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::group_by(isotype_antigen) %&gt;%\n  dplyr::summarize(is_antigen_specific_fraction = mean(is_antigen_specific)) %&gt;%\n  dplyr::arrange(is_antigen_specific_fraction)\n\n\n\n  \n\n\n\nSo the top entry makes sense, IgE_Total does not refer to any specific antigen\n\n\n9.3.2 Per Specimen\nSo in some specimen we have non-specific antibody measurements? What does that mean?\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(is_antigen_specific_fraction = mean(is_antigen_specific)) %&gt;%\n  ggplot(aes(x=is_antigen_specific_fraction)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n9.3.3 Per Year\nSo this is very weird. For 2021, no antibody measurement is antigen-specific? Maybe this is a bug!\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarize(mean_is_antigen_specific = mean(is_antigen_specific))"
  },
  {
    "objectID": "eda/raw_data_overview.html#nk",
    "href": "eda/raw_data_overview.html#nk",
    "title": "Data Overview",
    "section": "10.1 NK",
    "text": "10.1 NK\nThere are 3 types of NK cells:\n\nNK cells (CD3-CD19-CD56+): CD19-CD3-CD56+/++\nNK: CD19-CD3-CD56+\nCD56high NK cells: CD19-CD3-CD56++\n\nAnd I dont know what to do with that information!"
  },
  {
    "objectID": "eda/raw_data_overview.html#no-gating-info-for-2023",
    "href": "eda/raw_data_overview.html#no-gating-info-for-2023",
    "title": "Data Overview",
    "section": "10.2 No Gating Info for 2023",
    "text": "10.2 No Gating Info for 2023\n\nI just assume it is the same as in 2022, but this might not be true since the data look so different"
  },
  {
    "objectID": "eda/raw_data_overview.html#no-gating-info-for-basophils-and-cd19-in-2020",
    "href": "eda/raw_data_overview.html#no-gating-info-for-basophils-and-cd19-in-2020",
    "title": "Data Overview",
    "section": "10.3 No Gating Info for Basophils and CD19 in 2020",
    "text": "10.3 No Gating Info for Basophils and CD19 in 2020\n\nI just assume it is the same as in 2021 and 2022"
  },
  {
    "objectID": "eda/raw_data_overview.html#no-gating-info-for-non-pdcs-at-all",
    "href": "eda/raw_data_overview.html#no-gating-info-for-non-pdcs-at-all",
    "title": "Data Overview",
    "section": "10.4 No Gating Info for non-pDCs at all",
    "text": "10.4 No Gating Info for non-pDCs at all\nNot sure how to fix this)\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(is.na(level)) %&gt;%\n  dplyr::select(dataset, cell_type_name) %&gt;%\n  dplyr::distinct()"
  },
  {
    "objectID": "eda/raw_data_overview.html#should-the-proportions-sum-up-to-1-at-level-0",
    "href": "eda/raw_data_overview.html#should-the-proportions-sum-up-to-1-at-level-0",
    "title": "Data Overview",
    "section": "10.5 Should the Proportions sum up to 1 at level 0?",
    "text": "10.5 Should the Proportions sum up to 1 at level 0?\n\nTrying to take the hierarchical information into account, it still does not make sense\n\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(level == 0) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(percent_live_cell_sum = sum(percent_live_cell, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  ggplot() +\n  geom_violin(aes(x=dataset, y=percent_live_cell_sum)) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/raw_data_overview.html#difference-in-2023-dataset",
    "href": "eda/raw_data_overview.html#difference-in-2023-dataset",
    "title": "Data Overview",
    "section": "10.6 Difference in 2023 Dataset",
    "text": "10.6 Difference in 2023 Dataset\n\nIt seems like the 2023 data are very very different, which makes me hesitant to use it for any kind of predictions on the challenge data. E.g. just looking at level 0 which should make sense I get the following\n\n\n\nCode\n# first check for NAs for the levels\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(is.na(level))\n\n\n\n  \n\n\n\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(level == 0) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(percent_live_cell_sum = sum(percent_live_cell, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  ggplot() +\n  geom_violin(aes(x=dataset, y=percent_live_cell_sum)) +\n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\nEspecially, when completely ignoring the hierarchy in the gating information, I would expect to have more than 100% in percelt_live_cell_sum, but this is not true for the specimens from the 2023 dataset\n\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(percent_live_cell_sum = sum(percent_live_cell, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  ggplot() +\n  geom_violin(aes(x=dataset, y=percent_live_cell_sum)) +\n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\nOr what I use a list of predefined cell types of interest?"
  },
  {
    "objectID": "eda/filtered_data_overview.html",
    "href": "eda/filtered_data_overview.html",
    "title": "Data Overview",
    "section": "",
    "text": "Code\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(ggdark)\n  library(factoextra)\n  library(FactoMineR)\n  library(magick)\n  library(ComplexHeatmap)\n  library(circlize)\n})\n\nsource(file.path(\"..\", \"src\", \"read_data.R\"))\nsource(file.path(\"..\", \"src\", \"colors.R\"))"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-many-subjects-do-we-have-per-dataset-per-partition",
    "href": "eda/filtered_data_overview.html#how-many-subjects-do-we-have-per-dataset-per-partition",
    "title": "Data Overview",
    "section": "4.1 How many subjects do we have per dataset / per partition?",
    "text": "4.1 How many subjects do we have per dataset / per partition?\n\n\nCode\nmeta_data %&gt;%\n  dplyr::select(subject_id, dataset, partition, infancy_vac) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::count(dataset, partition, infancy_vac) %&gt;%\n  ggplot(aes(x = n, y = dataset, fill = infancy_vac, color = partition)) +\n  geom_col(position = position_dodge(width = 0.9), width = 0.7, alpha=0.5) +  \n  geom_text(aes(label = n), \n            position = position_dodge(width = 0.9),  \n            hjust = -0.2, vjust = 0.5, size = 3, color = \"white\") +\n  scale_fill_manual(values = infancy_vac_colors) +\n  scale_color_manual(values = partition_colors) +\n  ggdark::dark_mode(verbose = FALSE)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#what-is-the-age-range",
    "href": "eda/filtered_data_overview.html#what-is-the-age-range",
    "title": "Data Overview",
    "section": "4.2 What is the age range",
    "text": "4.2 What is the age range\n\n\nCode\nmeta_data %&gt;%\n  ggplot() + \n  geom_histogram(aes(x=age_at_boost, fill=dataset, y=after_stat(density)), \n                 color=\"black\", position=\"identity\", bins=30) +\n  facet_wrap(~dataset) +\n  scale_fill_manual(values=dataset_colors) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#what-is-the-difference-between-planned-and-actual-booster-administration",
    "href": "eda/filtered_data_overview.html#what-is-the-difference-between-planned-and-actual-booster-administration",
    "title": "Data Overview",
    "section": "5.1 What is the difference between planned and actual booster administration",
    "text": "5.1 What is the difference between planned and actual booster administration\n\n\nCode\nmeta_data %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=diff_relative_to_boost), binwidth=1) +\n  facet_wrap(~dataset) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#what-is-the-difference-between-planned-and-actual-for-the-baseline",
    "href": "eda/filtered_data_overview.html#what-is-the-difference-between-planned-and-actual-for-the-baseline",
    "title": "Data Overview",
    "section": "5.2 What is the difference between planned and actual for the baseline",
    "text": "5.2 What is the difference between planned and actual for the baseline\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==0) %&gt;%\n  dplyr::mutate(`diff_&gt;_15` = abs(actual_day_relative_to_boost) &gt; 15) %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=actual_day_relative_to_boost, fill=`diff_&gt;_15`), binwidth=1) +\n  facet_wrap(~dataset) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-many-time-points-do-we-have-per-subject",
    "href": "eda/filtered_data_overview.html#how-many-time-points-do-we-have-per-subject",
    "title": "Data Overview",
    "section": "5.3 How many time points do we have per subject?",
    "text": "5.3 How many time points do we have per subject?\n\n\nCode\nmeta_data %&gt;%\n  dplyr::count(dataset, subject_id) %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=n, fill=dataset),color=\"black\", binwidth=1) +\n  facet_wrap(~dataset, ncol=2) +\n  ggdark::dark_mode(verbose=FALSE) +\n  scale_x_continuous(breaks=seq(0, 8, 1)) +\n  scale_fill_manual(values=dataset_colors)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-many-assays-do-we-have-for-the-baseline-measurement",
    "href": "eda/filtered_data_overview.html#how-many-assays-do-we-have-for-the-baseline-measurement",
    "title": "Data Overview",
    "section": "5.4 How many assays do we have for the baseline measurement?",
    "text": "5.4 How many assays do we have for the baseline measurement?\n\n\nCode\nassays_per_specimen &lt;- purrr::imap(exp_data, ~ .x %&gt;% \n              dplyr::select(specimen_id) %&gt;%\n              dplyr::distinct() %&gt;%\n              dplyr::mutate(assay=.y)) %&gt;%\n  dplyr::bind_rows() %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::select(specimen_id, assay, subject_id, planned_day_relative_to_boost, infancy_vac, dataset)\n\nassays_per_specimen %&gt;%\n  dplyr::count(subject_id, planned_day_relative_to_boost, dataset, specimen_id) %&gt;%\n  dplyr::filter(!is.na(subject_id)) %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==0) %&gt;%\n  ggplot() +\n  geom_histogram(aes(x=n, fill=dataset), color=\"black\", binwidth=1) +\n  facet_wrap(~dataset, ncol=2) +\n  ggdark::dark_mode(verbose=FALSE) +\n  scale_x_continuous(breaks=seq(0, 8, 1)) +\n  scale_fill_manual(values=dataset_colors)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor (day in c(0, 1, 3, 14)) {\n  \nannotation_data &lt;- meta_data %&gt;%\n  dplyr::select(specimen_id, planned_day_relative_to_boost, infancy_vac, \n                dataset, biological_sex) %&gt;%\n  dplyr::filter(specimen_id %in% assays_per_specimen$specimen_id) %&gt;%\n  dplyr::filter(planned_day_relative_to_boost == !!day) %&gt;% \n  dplyr::select(- planned_day_relative_to_boost) %&gt;%\n  dplyr::arrange(dataset, infancy_vac, biological_sex) %&gt;%\n  tibble::column_to_rownames(\"specimen_id\") %&gt;%\n  dplyr::select(dataset, infancy_vac, biological_sex)\n\nheatmap_data &lt;- assays_per_specimen %&gt;%\n  dplyr::select(specimen_id, assay) %&gt;%\n  dplyr::mutate(value = 1) %&gt;%\n  tidyr::pivot_wider(names_from=\"assay\", values_from=\"value\") %&gt;%\n  mutate(across(everything(), .fns = ~replace_na(.,0))) %&gt;%\n  tibble::column_to_rownames(\"specimen_id\") %&gt;%\n  as.matrix() %&gt;%\n  t()\n\ncolnames(heatmap_data) &lt;- as.character(colnames(heatmap_data))\nheatmap_data &lt;- heatmap_data[, rownames(annotation_data)]\n\n# Create the heatmap\nht &lt;- Heatmap(heatmap_data, \n              name = \"heatmap\", \n              row_title = \"\", \n              column_title = paste0(\"Specimens for Planned Day \", day),\n              col = colorRamp2(c(0, 1), c(\"white\", \"black\")),\n              cluster_rows = FALSE,\n              cluster_columns = FALSE,\n              show_row_names = TRUE, \n              show_column_names = FALSE,\n              width = unit(16, \"cm\"),\n              top_annotation = ComplexHeatmap::HeatmapAnnotation(df = annotation_data,\n                                    col = list(\n                                      \"dataset\" = dataset_colors,\n                                      \"infancy_vac\" = infancy_vac_colors,\n                                      \"biological_sex\" = sex_colors\n                                    ),\n                                    which=\"column\")\n)\n\ndraw(ht, \n     heatmap_legend_side = \"top\",\n     annotation_legend_side = \"top\",\n     show_heatmap_legend = FALSE # don't show colorbar\n     )\n}"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-many-subjects-can-we-use-to-construct-training-data",
    "href": "eda/filtered_data_overview.html#how-many-subjects-can-we-use-to-construct-training-data",
    "title": "Data Overview",
    "section": "6.1 How many subjects can we use to construct training data?",
    "text": "6.1 How many subjects can we use to construct training data?\n\n6.1.1 1) Antibody Level Tasks (anti-PT 14 days after booster)\n\nAll but 7 people were assayed approximately 14 days after the booster administration\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==14) %&gt;%\n  ggplot(aes(x=diff_relative_to_boost)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::select(subject_id, infancy_vac, dataset, biological_sex, ethnicity, race, year_of_birth) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::mutate(task_1_possible = \n                  subject_id %in% (meta_data %&gt;%\n                                     dplyr::filter(planned_day_relative_to_boost==14) %&gt;%\n                                     dplyr::left_join(exp_data$plasma_ab_titer,\n                                                      by=\"specimen_id\") %&gt;%\n                                     dplyr::filter(isotype_antigen==\"IgG_PT\") %&gt;%\n                                     tidyr::drop_na() %&gt;%\n                                     dplyr::pull(subject_id))\n  ) %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarise(task_1_possible_total = sum(task_1_possible), \n                   task_1_possible_fraction = mean(task_1_possible))\n\n\n\n  \n\n\n\n\n\n6.1.2 2) Cell Frequency Tasks (Monocytes 1 day after booster)\n\nBut there is one person where it does not really make sense\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==1) %&gt;%\n  ggplot(aes(x=diff_relative_to_boost)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::select(subject_id, infancy_vac, dataset, biological_sex, ethnicity, race, year_of_birth) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::mutate(task_possible = \n                  subject_id %in% (meta_data %&gt;%\n                                     dplyr::filter(planned_day_relative_to_boost==1) %&gt;%\n                                     dplyr::left_join(exp_data$pbmc_cell_frequency, by=\"specimen_id\") %&gt;%\n                                     dplyr::filter(cell_type_name==\"Monocytes\") %&gt;%\n                                     tidyr::drop_na() %&gt;%\n                                     dplyr::pull(subject_id))\n  ) %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarise(task_possible_total = sum(task_possible), \n                   task_possible_fraction = mean(task_possible))\n\n\n\n  \n\n\n\n\n\n6.1.3 3) Gene Expression Tasks (CCL3 expression 3 days after booster)\n\nThere are 7 people for which this task does nto make sense\n\n\n\nCode\nmeta_data %&gt;%\n  dplyr::filter(planned_day_relative_to_boost==3) %&gt;%\n  ggplot(aes(x=diff_relative_to_boost)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nall_genes &lt;- unique(exp_data$pbmc_gene_expression$versioned_ensembl_gene_id)\nccl3_ensembl &lt;- \"ENSG00000277632\"\nccl3_ensembl_versioned &lt;- all_genes[str_starts(all_genes, ccl3_ensembl)]\n\nmeta_data %&gt;%\n  dplyr::select(subject_id, infancy_vac, dataset, biological_sex, ethnicity, race, year_of_birth) %&gt;%\n  dplyr::distinct() %&gt;%\n  dplyr::mutate(task_possible = \n                  subject_id %in% (meta_data %&gt;%\n                                     dplyr::filter(planned_day_relative_to_boost==3) %&gt;%\n                                     dplyr::left_join(exp_data$pbmc_gene_expression, by=\"specimen_id\") %&gt;%\n                                     dplyr::filter(versioned_ensembl_gene_id==ccl3_ensembl_versioned) %&gt;%\n                                     tidyr::drop_na() %&gt;%\n                                     dplyr::pull(subject_id))\n  ) %&gt;%\n  dplyr::group_by(dataset) %&gt;%\n  dplyr::summarise(task_possible_total = sum(task_possible), \n                   task_possible_fraction = mean(task_possible))"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-many-na-values-do-we-have-per-assay",
    "href": "eda/filtered_data_overview.html#how-many-na-values-do-we-have-per-assay",
    "title": "Data Overview",
    "section": "7.1 How many NA values do we have per assay?",
    "text": "7.1 How many NA values do we have per assay?\n\n\nCode\npurrr::imap(exp_data, function(df, modality) {\n  feature_col &lt;- experimental_data_settings[[modality]]$feature_col\n  value_col &lt;- experimental_data_settings[[modality]]$value_col\n  tibble(modality = modality, feature_col = feature_col, sum_na = sum(is.na(df[[value_col]])))\n}) %&gt;%\n  dplyr::bind_rows()"
  },
  {
    "objectID": "eda/filtered_data_overview.html#wide-format",
    "href": "eda/filtered_data_overview.html#wide-format",
    "title": "Data Overview",
    "section": "7.2 Wide format",
    "text": "7.2 Wide format\n\n\nCode\npurrr::imap_dfr(generate_wide_experimental_data(experimental_data=exp_data, \n                                                impute=NULL),\n                  function(mtx, modality) {\n                    rmeans &lt;- rowMeans(is.na(mtx))\n                    tibble(modality=modality, \n                           subject_id = names(rmeans), \n                           na_frac=rmeans)\n           }) %&gt;%\n  dplyr::group_by(modality) %&gt;%\n  dplyr::summarise(mean_na_frac = mean(na_frac))\n\n\nplasma_cytokine_concentration_by_olink | NA Fraction: 0.0110795454545455 | Removed samples: 760, 750, 903, 824, 894, 833\n\n\nt_cell_activation | NA Fraction: 0.0576923076923077 | Removed samples: 681"
  },
  {
    "objectID": "eda/filtered_data_overview.html#what-is-the-fraction-of-na-values-in-the-pbmc-cell-type-frequencies",
    "href": "eda/filtered_data_overview.html#what-is-the-fraction-of-na-values-in-the-pbmc-cell-type-frequencies",
    "title": "Data Overview",
    "section": "7.3 What is the fraction of NA values in the PBMC Cell Type Frequencies",
    "text": "7.3 What is the fraction of NA values in the PBMC Cell Type Frequencies\nWith the current selection of cell types, there is no specimen with NA values.\n\n7.3.1 Per Cell Type\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::mutate(is_na = is.na(percent_live_cell)) %&gt;%\n  dplyr::group_by(cell_type_name) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  dplyr::arrange(desc(frac_na)) %&gt;%\n  dplyr::mutate(cell_type_name = factor(cell_type_name, levels=rev(cell_type_name))) %&gt;%\n  ggplot() +\n  geom_col(aes(y=cell_type_name, x=frac_na)) +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Cell Type\")\n\n\n\n\n\n\n\n\n\n\n\n7.3.2 Per Cell Specimen\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::mutate(is_na = is.na(percent_live_cell)) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  ggplot(aes(x = frac_na)) +\n  geom_histogram(bins = 20, color = \"white\", fill = \"blue\", alpha=0.1) +  # Add color for better visibility\n  stat_bin(aes(label = after_stat(count)), bins = 20, geom = \"text\", \n           vjust = -0.5, color = \"white\", size = 3) +  # Display bin counts at the top\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Specimen\")"
  },
  {
    "objectID": "eda/filtered_data_overview.html#what-is-the-fraction-of-na-values-in-the-olink-data",
    "href": "eda/filtered_data_overview.html#what-is-the-fraction-of-na-values-in-the-olink-data",
    "title": "Data Overview",
    "section": "7.4 What is the fraction of NA values in the Olink Data?",
    "text": "7.4 What is the fraction of NA values in the Olink Data?\n\n7.4.1 Per Protein\nAfter excluding Q969D9, the largest fraction of NA values is about 5% which is acceptable I guess.\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(is_na = is.na(concentration)) %&gt;%\n  dplyr::group_by(protein_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  dplyr::arrange(desc(frac_na)) %&gt;%\n  dplyr::mutate(protein_id = factor(protein_id, levels=rev(protein_id))) %&gt;%\n  ggplot() +\n  geom_col(aes(y=protein_id, x=frac_na)) +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Protein\")\n\n\n\n\n\n\n\n\n\n\n\n7.4.2 Per Specimen\nThere are 6 specimen with more than 50% NA values, I am not sure whether I should exlcude those?\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(is_na = is.na(concentration)) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  ggplot(aes(x = frac_na)) +\n  geom_histogram(bins = 20, color = \"white\", fill = \"blue\", alpha=0.1) +  # Add color for better visibility\n  stat_bin(aes(label = after_stat(count)), bins = 20, geom = \"text\", \n           vjust = -0.5, color = \"white\", size = 3) +  # Display bin counts at the top\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Fraction of NA Values per Specimen\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(is_na = is.na(concentration)) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarise(frac_na = sum(is_na) / n()) %&gt;%\n  dplyr::filter(frac_na &gt; 0.2) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::select(specimen_id, frac_na, subject_id, dataset, \n                actual_day_relative_to_boost, planned_day_relative_to_boost)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-does-the-quality-control-for-olink-look-like",
    "href": "eda/filtered_data_overview.html#how-does-the-quality-control-for-olink-look-like",
    "title": "Data Overview",
    "section": "8.1 How does the quality control for Olink look like?",
    "text": "8.1 How does the quality control for Olink look like?\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::count(quality_control)\n\n\n\n  \n\n\n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::count(partition, dataset)\n\n\n\n  \n\n\n\nCode\nexp_data$plasma_cytokine_concentration_by_legendplex %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  dplyr::count(partition, dataset)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#how-often-is-the-cytokine-concentration-below-the-lod-in-olink",
    "href": "eda/filtered_data_overview.html#how-often-is-the-cytokine-concentration-below-the-lod-in-olink",
    "title": "Data Overview",
    "section": "8.2 How often is the Cytokine Concentration below the LOD in Olink",
    "text": "8.2 How often is the Cytokine Concentration below the LOD in Olink\n\n\nCode\n# check how often is it below the limit of detection?\nexp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(below_lod = concentration &lt; lower_limit_of_quantitation) %&gt;%\n  dplyr::count(below_lod)\n\n\n\n  \n\n\n\n\n\nCode\nset.seed(1)\np1 &lt;- exp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(below_lod = concentration &lt; lower_limit_of_quantitation) %&gt;%\n  dplyr::mutate(qc_warning = quality_control == \"Warning\") %&gt;%\n  dplyr::group_by(protein_id) %&gt;%\n  dplyr::summarize(mean_below_lod = mean(below_lod, na.rm=TRUE),\n                   mean_qc_warning = mean(qc_warning, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(cytokine_uniprot_mapping, by=\"protein_id\") %&gt;%\n  ggplot() +\n  geom_point(aes(x = mean_below_lod, y = mean_qc_warning)) +\n  ggrepel::geom_text_repel(aes(x = mean_below_lod, y = mean_qc_warning, \n                      label = ifelse(mean_below_lod &gt; 0.2, protein_id, '')),\n                  max.overlaps = Inf, color=\"grey\") + # This ensures all labels are shown\n  ggdark::dark_mode()\n\np2 &lt;- exp_data$plasma_cytokine_concentration_by_olink %&gt;%\n  dplyr::mutate(below_lod = concentration &lt; lower_limit_of_quantitation) %&gt;%\n  dplyr::mutate(qc_warning = quality_control == \"Warning\") %&gt;%\n  dplyr::group_by(protein_id) %&gt;%\n  dplyr::summarize(mean_below_lod = mean(below_lod, na.rm=TRUE),\n                   mean_qc_warning = mean(qc_warning, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(cytokine_uniprot_mapping, by=\"protein_id\") %&gt;%\n  ggplot() +\n  geom_point(aes(x = mean_below_lod, y = mean_qc_warning)) +\n  ggrepel::geom_text_repel(aes(x = mean_below_lod, y = mean_qc_warning, \n                      label = ifelse(mean_below_lod &gt; 0.2, cytokine, '')),\n                  max.overlaps = Inf, color=\"grey\") + # This ensures all labels are shown\n  ggdark::dark_mode()\n\ncowplot::plot_grid(p1, p2, ncol=2)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#what-is-the-fraction-of-unspecific-antibody-measurements",
    "href": "eda/filtered_data_overview.html#what-is-the-fraction-of-unspecific-antibody-measurements",
    "title": "Data Overview",
    "section": "8.3 What is the fraction of unspecific antibody measurements",
    "text": "8.3 What is the fraction of unspecific antibody measurements\n\n8.3.1 Per Isotype-Antigen\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::group_by(isotype_antigen) %&gt;%\n  dplyr::summarize(is_antigen_specific_fraction = mean(is_antigen_specific)) %&gt;%\n  ggplot(aes(x=is_antigen_specific_fraction)) +\n  geom_histogram(bins=30, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), bins=30, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n8.3.2 Per Specimen\nSo in some specimen we have non-specific antibody measurements? What does that mean?\n\n\nCode\nexp_data$plasma_ab_titer %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(is_antigen_specific_fraction = mean(is_antigen_specific)) %&gt;%\n  ggplot(aes(x=is_antigen_specific_fraction)) +\n  geom_histogram(binwidth=1, color = \"white\", fill = \"blue\", alpha=0.1) +\n  stat_bin(aes(label = after_stat(count)), binwidth=1, geom = \"text\", vjust = -0.5, color = \"white\", size = 3) +  \n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#nk",
    "href": "eda/filtered_data_overview.html#nk",
    "title": "Data Overview",
    "section": "9.1 NK",
    "text": "9.1 NK\nThere are 3 types of NK cells:\n\nNK cells (CD3-CD19-CD56+): CD19-CD3-CD56+/++\nNK: CD19-CD3-CD56+\nCD56high NK cells: CD19-CD3-CD56++\n\nAnd I dont know what to do with that information!"
  },
  {
    "objectID": "eda/filtered_data_overview.html#no-gating-info-for-2023",
    "href": "eda/filtered_data_overview.html#no-gating-info-for-2023",
    "title": "Data Overview",
    "section": "9.2 No Gating Info for 2023",
    "text": "9.2 No Gating Info for 2023\n\nI just assume it is the same as in 2022, but this might not be true since the data look so different"
  },
  {
    "objectID": "eda/filtered_data_overview.html#no-gating-info-for-basophils-and-cd19-in-2020",
    "href": "eda/filtered_data_overview.html#no-gating-info-for-basophils-and-cd19-in-2020",
    "title": "Data Overview",
    "section": "9.3 No Gating Info for Basophils and CD19 in 2020",
    "text": "9.3 No Gating Info for Basophils and CD19 in 2020\n\nI just assume it is the same as in 2021 and 2022"
  },
  {
    "objectID": "eda/filtered_data_overview.html#no-gating-info-for-non-pdcs-at-all",
    "href": "eda/filtered_data_overview.html#no-gating-info-for-non-pdcs-at-all",
    "title": "Data Overview",
    "section": "9.4 No Gating Info for non-pDCs at all",
    "text": "9.4 No Gating Info for non-pDCs at all\nNot sure how to fix this)\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(is.na(level)) %&gt;%\n  dplyr::select(dataset, cell_type_name) %&gt;%\n  dplyr::distinct()"
  },
  {
    "objectID": "eda/filtered_data_overview.html#should-the-proportions-sum-up-to-1-at-level-0",
    "href": "eda/filtered_data_overview.html#should-the-proportions-sum-up-to-1-at-level-0",
    "title": "Data Overview",
    "section": "9.5 Should the Proportions sum up to 1 at level 0?",
    "text": "9.5 Should the Proportions sum up to 1 at level 0?\n\nTrying to take the hierarchical information into account, it still does not make sense\n\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(level == 0) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(percent_live_cell_sum = sum(percent_live_cell, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  ggplot() +\n  geom_violin(aes(x=dataset, y=percent_live_cell_sum)) +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "eda/filtered_data_overview.html#difference-in-2023-dataset",
    "href": "eda/filtered_data_overview.html#difference-in-2023-dataset",
    "title": "Data Overview",
    "section": "9.6 Difference in 2023 Dataset",
    "text": "9.6 Difference in 2023 Dataset\n\nIt seems like the 2023 data are very very different, which makes me hesitant to use it for any kind of predictions on the challenge data. E.g. just looking at level 0 which should make sense I get the following\n\n\n\nCode\n# first check for NAs for the levels\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(is.na(level))\n\n\n\n  \n\n\n\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::filter(level == 0) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(percent_live_cell_sum = sum(percent_live_cell, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  ggplot() +\n  geom_violin(aes(x=dataset, y=percent_live_cell_sum)) +\n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\nEspecially, when completely ignoring the hierarchy in the gating information, I would expect to have more than 100% in percelt_live_cell_sum, but this is not true for the specimens from the 2023 dataset\n\n\n\nCode\nexp_data$pbmc_cell_frequency %&gt;%\n  dplyr::left_join((meta_data %&gt;%\n                      dplyr::select(specimen_id, dataset) %&gt;%\n                      dplyr::distinct()),\n                   by=\"specimen_id\") %&gt;%\n  dplyr::left_join((celltype_meta %&gt;%\n                      dplyr::select(cell_type_name, dataset, level) %&gt;%\n                      dplyr::distinct()),\n                    by=c(\"dataset\", \"cell_type_name\")) %&gt;%\n  dplyr::group_by(specimen_id) %&gt;%\n  dplyr::summarize(percent_live_cell_sum = sum(percent_live_cell, na.rm=TRUE)) %&gt;%\n  dplyr::left_join(meta_data, by=\"specimen_id\") %&gt;%\n  ggplot() +\n  geom_violin(aes(x=dataset, y=percent_live_cell_sum)) +\n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\nOr what I use a list of predefined cell types of interest?"
  }
]